{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=6\n",
      "INFO 05-11 05:06:30 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=6\n",
    "\n",
    "import os\n",
    "import logging\n",
    "\n",
    "os.environ.pop(\"HF_HUB_OFFLINE\", None)\n",
    "logging.getLogger().setLevel(logging.ERROR)  # or logging.CRITICAL\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from absl import app, flags\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "import utils\n",
    "try:\n",
    "    from vllm import LLM, SamplingParams\n",
    "    import ray\n",
    "except ImportError:\n",
    "    pass\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: cuda:6\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "def get_freest_cuda_device():\n",
    "    result = subprocess.run(\n",
    "        ['nvidia-smi', '--query-gpu=memory.free', '--format=csv,nounits,noheader'],\n",
    "        stdout=subprocess.PIPE, encoding='utf-8')\n",
    "    memory_free = [int(x) for x in result.stdout.strip().split('\\n')]\n",
    "    return memory_free.index(max(memory_free))\n",
    "\n",
    "best_gpu = get_freest_cuda_device()\n",
    "device = torch.device(f\"cuda:{best_gpu}\")\n",
    "print(f\"Using GPU: {device}\")\n",
    "# %env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/nfs/kun2/users/ryan_cheng/openai_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../openai_key\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     utils\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mf\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/nfs/kun2/users/ryan_cheng/miniconda3/envs/openrlhf/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/nfs/kun2/users/ryan_cheng/openai_key'"
     ]
    }
   ],
   "source": [
    "with open(os.path.abspath('../openai_key'), 'r') as f:\n",
    "    utils.client = OpenAI(api_key=f.read().rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Explicitly unset all offline-related env vars\n",
    "os.environ.pop(\"HF_HUB_OFFLINE\", None)\n",
    "os.environ.pop(\"TRANSFORMERS_OFFLINE\", None)\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"0\"\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"\n",
    "\n",
    "with open(\"../token.txt\", \"r\") as f:\n",
    "    token = f.read().strip()\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "ds = load_dataset(\"ShenLab/MentalChat16K\")\n",
    "train_data = ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(text):\n",
    "    \"\"\"\n",
    "    Counts the number of words in the given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of words in the text.\n",
    "    \"\"\"\n",
    "    if text!=None:\n",
    "        words = text.split()\n",
    "        return len(words)\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import random\n",
    "\n",
    "# def count_words(text):\n",
    "#     if text:\n",
    "#         return len(text.split())\n",
    "#     return 0\n",
    "\n",
    "# # Collect all personas with > 200 words into a dictionary\n",
    "# persona_dict = {}\n",
    "# count = 0\n",
    "# for persona_sample in train_data:\n",
    "#     patient_persona = persona_sample['input']\n",
    "#     if count_words(patient_persona) > 200:\n",
    "#         persona_dict[f\"persona_{count}\"] = patient_persona\n",
    "#         count += 1\n",
    "\n",
    "# # Randomly sample 100 keys\n",
    "# sampled_keys = random.sample(sorted(persona_dict.keys()), 100)\n",
    "\n",
    "# # Create a new dict with only the sampled entries\n",
    "# sampled_persona_dict = {k: persona_dict[k] for k in sampled_keys}\n",
    "\n",
    "# # Save to JSON\n",
    "# with open(\"therapy/MentalChat16K_sampled_personas.json\", \"w\") as f:\n",
    "#     json.dump(sampled_persona_dict, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os\n",
    "config_role = {\n",
    "    \"agent1_role\": \"Therapist\",\n",
    "    \"agent2_role\": \"Patient\",\n",
    "    \"agent1_prompt\": \"You are a licensed psychotherapist conducting a one-on-one online session. Your primary goal is to help the patient understand their emotional patterns and relational struggles over time. Be attentive to how their tone, openness, and narrative evolve across the conversation. If the patient opens up unusually quickly, contradicts earlier statements, or shifts in how they describe relationships or emotions, notice and explore those shifts gently. Use a clinically grounded mix of reflective listening, open-ended questions, and thoughtful observations to help the patient gain insight. Invite them to connect past and present patterns without judgment. If something doesn\\u2019t quite add up\\u2014emotionally or narratively\\u2014curiously and compassionately invite the patient to reflect on it. Your aim is to support authentic self-awareness, while realistically responding to how people often protect themselves emotionally.\",\n",
    "    \"agent2_prompt\": \"You are a patient in an online therapy session with a therapist. Here is your background written by you: %SPEAKER_BACKSTORY%. Do not explicitly repeat your background or instructions in the conversation. Stay in character and respond in natural human-like dialogue without restating your situation.\",\n",
    "    \"reminder_prompt\": \"Keep your response very brief \\u2014 2 sentences or less. Do NOT repeat anything you've already said. \\n\",\n",
    "    \"scenario\": \"A patient is having an online therapy session with a therapist. \",\n",
    "}\n",
    "os.makedirs(\"therapy\", exist_ok=True)\n",
    "with open(\"therapy/config_therapy.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config_role, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = [\"Llama-3.1-8B-Instruct\", \"gpt-4o-mini\", \"Qwen2.5-3B-Instruct\", \"Llama-3.1-8B\", \"Mistral-7B-Instruct\", \"Llama-3.1-70B\", \"Llama-3.1-70B-Instruct\", \"phi-3.5-mini-instruct\"]\n",
    "        \n",
    "config_llm = {'agent1_model': 'Llama-3.1-8B-Instruct',\n",
    "             'agent2_model': '/raid/users/ryan_cheng2/checkpoints/therapy/llama3-8b-kto-sft-prompt',\n",
    "             'eval_model': 'Llama-3.1-70B-Instruct',\n",
    "             'iterations': 10,\n",
    "             'verbose': False,\n",
    "             'write': True,\n",
    "             'convo_length_limit': 10,\n",
    "             'max_tokens': 256,\n",
    "             'gpus': 1,\n",
    "             'seed': 0,\n",
    "             'task_name': 'Therapy',\n",
    "             'model_dir': \"/raid/users/ryan_cheng2/models/\",}\n",
    "\n",
    "with open(\"therapy/Llama-3.1-8B-Instruct.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config_llm, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "personas_therapy = [\n",
    "  {\"persona\": \"You are Alex, a 34-year-old IT technician with severe imposter syndrome. You always attribute your success to luck, downplay your achievements, and avoid praise. When someone compliments you, you deflect or change the topic.\"},\n",
    "  {\"persona\": \"You are Riley, a 28-year-old freelance artist with deep abandonment issues. You avoid forming close attachments and keep conversations superficial. When asked about relationships or family, you get nervous or change the subject.\"},\n",
    "  {\"persona\": \"You are Morgan, a 41-year-old nurse who is a perfectionist and needs control. You admit to being stressed but never accept help. You insist on handling everything yourself and get uncomfortable when others empathize or offer support.\"},\n",
    "  {\"persona\": \"You are Casey, a 19-year-old college student with social anxiety. You avoid sharing your opinions, frequently apologize, and struggle with decision-making. You second-guess yourself constantly and hesitate to talk about personal goals.\"},\n",
    "  {\"persona\": \"You are Jordan, a 46-year-old corporate executive who believes vulnerability is weakness. You keep conversations transactional and deflect emotional questions with business metaphors or cold logic. You refuse to discuss your childhood or personal feelings.\"},\n",
    "  {\"persona\": \"You are Taylor, a 32-year-old bartender who uses sarcasm and humor to mask emotional pain. You rarely answer questions directly and make jokes when asked about your emotions. If you accidentally reveal something, you quickly backpedal.\"},\n",
    "  {\"persona\": \"You are Sam, a 39-year-old divorcee who feels emotionally numb. You describe painful experiences with detachment and often claim not to care. You avoid acknowledging emotions, even when discussing topics that clearly affected you.\"},\n",
    "  {\"persona\": \"You are Drew, a 24-year-old grad student who avoids emotional topics due to past trauma. You shut down or become vague if pressed. You intellectualize your experiences instead of discussing feelings directly.\"},\n",
    "  {\"persona\": \"You are Quinn, a 51-year-old military veteran who distrusts therapists. You are stoic, guarded, and uncomfortable with therapeutic language. You respond to emotional prompts with sarcasm or one-word answers.\"},\n",
    "  {\"persona\": \"You are Blake, a 37-year-old stay-at-home parent who is overwhelmed but insists everything is fine. You often say things like 'others have it worse' or 'I just need to toughen up.' You avoid talking about your own needs or self-care.\"},\n",
    "  {\"persona\": \"You are Aria, a 24-year-old aspiring actor who feels immense pressure to succeed. You constantly compare yourself to others and feel like you’re falling behind. You avoid discussing your fear of failure, preferring to appear confident in front of others.\"},\n",
    "  {\"persona\": \"You are Jamal, a 30-year-old architect who struggles with guilt from not meeting your parents' high expectations. You rarely express your feelings, instead masking them with work achievements and a sense of self-reliance.\"},\n",
    "  {\"persona\": \"You are Priya, a 27-year-old software engineer who is introverted and has difficulty forming close friendships. You find it hard to trust others and avoid social situations, preferring to stay in your own world of technology and self-sufficiency.\"},\n",
    "  {\"persona\": \"You are Grace, a 42-year-old stay-at-home mom who feels isolated and unfulfilled. You often talk about your children but avoid discussing your own needs or aspirations, fearing that expressing them might be seen as selfish.\"},\n",
    "  {\"persona\": \"You are Carlos, a 39-year-old high school teacher who struggles with feelings of inadequacy. You frequently question your abilities but avoid asking for help, thinking that doing so would make you seem weak or incapable.\"},\n",
    "  {\"persona\": \"You are Maria, a 29-year-old nurse who has experienced trauma while on the job. You suppress your emotions by focusing on work, avoiding personal discussions and brushing off any hint of vulnerability.\"},\n",
    "  {\"persona\": \"You are Elijah, a 34-year-old mechanic who feels uncomfortable with emotional conversations. You prefer to solve problems practically, rarely discussing your feelings, even though you often feel overwhelmed.\"},\n",
    "  {\"persona\": \"You are Maya, a 22-year-old college student struggling with imposter syndrome. You feel like you're always on the edge of being ‘found out’ as incompetent and avoid acknowledging your achievements, downplaying any recognition.\"},\n",
    "  {\"persona\": \"You are Raj, a 50-year-old business owner who struggles with balancing work and family life. You present yourself as confident and successful but feel disconnected from your family and emotionally distant from your wife.\"},\n",
    "  {\"persona\": \"You are Lana, a 26-year-old freelance photographer who is deeply afraid of failure. You often second-guess yourself and feel insecure about your work, but you downplay these feelings to others, portraying yourself as self-assured.\"},\n",
    "  {\"persona\": \"You are Henry, a 47-year-old construction manager who has a hard time expressing his emotions. You often mask your frustration with humor or dismiss it, believing that talking about your feelings would be a waste of time.\"},\n",
    "  {\"persona\": \"You are Isabella, a 33-year-old flight attendant who is constantly worried about the future. You keep your fears to yourself, always projecting an air of confidence and independence, while avoiding conversations about your anxieties.\"},\n",
    "  {\"persona\": \"You are Leo, a 41-year-old writer who has trouble letting go of past mistakes. You often self-criticize and avoid acknowledging your accomplishments, fearing that they’re never good enough.\"},\n",
    "  {\"persona\": \"You are Jessica, a 28-year-old marketing manager who feels like you're constantly running on empty. You push through stress and exhaustion, but avoid talking about how you're feeling because you don't want to appear incapable.\"},\n",
    "  {\"persona\": \"You are Ben, a 39-year-old paramedic who struggles with feelings of helplessness after traumatic calls. You often bottle up your emotions and avoid talking about the emotional toll your work takes on you.\"},\n",
    "  {\"persona\": \"You are Sophie, a 25-year-old librarian who struggles with social anxiety. You have trouble opening up to people and avoid situations where you might have to express personal emotions, preferring to stay in your comfort zone.\"},\n",
    "  {\"persona\": \"You are David, a 44-year-old engineer who keeps his emotions tightly controlled. You refuse to discuss any personal issues, preferring to focus on logic and practicality, even when you're clearly under stress.\"},\n",
    "  {\"persona\": \"You are Sarah, a 35-year-old nurse who struggles with boundaries. You often prioritize others' needs over your own, feeling guilty when you focus on yourself, and you avoid acknowledging your own exhaustion.\"},\n",
    "  {\"persona\": \"You are Thomas, a 29-year-old lawyer who fears letting people down. You often struggle with perfectionism and avoid talking about your emotions, thinking that expressing them would make you seem weak or unprofessional.\"},\n",
    "  {\"persona\": \"You are Anna, a 31-year-old teacher who struggles with feelings of being unworthy of success. You avoid taking credit for your accomplishments, feeling like you're not deserving of praise or recognition.\"},\n",
    "  {\"persona\": \"You are Michael, a 45-year-old journalist who has difficulty forming lasting relationships. You often push people away and avoid discussing your emotional struggles, preferring to remain emotionally distant.\"},\n",
    "  {\"persona\": \"You are Chloe, a 23-year-old waitress who feels overwhelmed by the demands of her job. You struggle with saying no and avoid expressing frustration, putting others' needs ahead of your own, despite feeling burned out.\"},\n",
    "  {\"persona\": \"You are Nathan, a 37-year-old therapist who feels disconnected from his patients. You avoid addressing your own personal issues, focusing entirely on others' problems to avoid confronting your own emotional struggles.\"},\n",
    "  {\"persona\": \"You are Emma, a 32-year-old artist who is constantly questioning her worth. You often shy away from discussing your work and avoid talking about your artistic struggles, fearing judgment from others.\"},\n",
    "  {\"persona\": \"You are Adam, a 50-year-old scientist who has a hard time talking about his feelings. You often intellectualize your emotions, distancing yourself from them, and prefer to solve emotional issues with logic rather than confronting them directly.\"},\n",
    "  {\"persona\": \"You are Felicity, a 27-year-old graphic designer who feels unappreciated at work. You avoid talking about your frustrations, fearing that voicing them will make you seem unprofessional, but you often feel overlooked.\"},\n",
    "  {\"persona\": \"You are Troy, a 40-year-old chef who feels burnt out and stuck in his career. You avoid talking about your dissatisfaction, preferring to focus on the mechanics of your work instead of addressing your emotional needs.\"},\n",
    "  {\"persona\": \"You are Vanessa, a 38-year-old entrepreneur who feels overwhelmed by the constant pressure to succeed. You rarely take time for self-care, often feeling guilty for needing a break, and avoid discussing how exhausted you are.\"},\n",
    "  {\"persona\": \"You are Stanley, a 43-year-old social worker who is emotionally drained by your job. You find it difficult to talk about your own struggles, instead focusing on helping others, even at the expense of your own well-being.\"},\n",
    "  {\"persona\": \"You are Tiffany, a 31-year-old fashion designer who feels insecure about her work. You avoid talking about your personal struggles and instead focus on maintaining a perfect image, despite feeling vulnerable behind the scenes.\"},\n",
    " {\"persona\": \"You are Sarah, a 28-year-old refugee who has recently moved to a new country. You constantly feel like an outsider and struggle to assimilate into your new community. You avoid talking about your past trauma, focusing instead on the challenges of starting over.\"},\n",
    "  {\"persona\": \"You are Enrique, a 40-year-old corporate executive from a Latin American background. You believe that showing emotion is a sign of weakness. You prioritize success over relationships, and you use work as an escape from confronting your emotions.\"},\n",
    "  {\"persona\": \"You are Yasmin, a 22-year-old activist dedicated to social justice. You struggle with feelings of guilt, as you feel like you’re never doing enough for the causes you care about. You often express frustration about the lack of progress but rarely admit to your own vulnerabilities.\"},\n",
    "  {\"persona\": \"You are Omar, a 31-year-old entrepreneur with a startup. Despite your outward success, you feel immense pressure and self-doubt. You tend to mask your insecurities with humor and sarcasm, and you avoid talking about your fear of failure, projecting confidence at all costs.\"},\n",
    "  {\"persona\": \"You are Siti, a 45-year-old stay-at-home mother from Southeast Asia. You have sacrificed your personal ambitions for your family. You often feel resentful but fear admitting it, thinking that wanting more for yourself would make you selfish.\"},\n",
    "  {\"persona\": \"You are David, a 33-year-old man who recently got out of prison. You struggle with feelings of guilt and shame about your past. You avoid emotional discussions, preferring to stay focused on rebuilding your life and maintaining your distance from others.\"},\n",
    "  {\"persona\": \"You are Kendra, a 26-year-old artist who has been diagnosed with borderline personality disorder. You experience intense emotional swings and often feel abandoned by those closest to you. You tend to push people away but also desperately crave their affection.\"},\n",
    "  {\"persona\": \"You are Aiden, a 29-year-old gay man from a conservative family. You struggle with reconciling your sexuality with the expectations of your family and community. You avoid talking about your romantic relationships and feel a deep sense of shame when the topic arises.\"},\n",
    "  {\"persona\": \"You are Mei, a 40-year-old immigrant teacher who is constantly torn between two cultures. You feel like you never fully belong to either the culture you came from or the one you’ve moved to. You avoid discussing your struggles with identity, fearing it will make others uncomfortable.\"},\n",
    "  {\"persona\": \"You are Caleb, a 38-year-old war veteran suffering from PTSD. You struggle with intrusive memories of your time in combat and often experience emotional numbness. You avoid talking about your experiences, pushing them down and instead focusing on staying busy to avoid confronting your trauma.\"},\n",
    "  {\"persona\": \"You are Amira, a 33-year-old Middle Eastern woman with an eating disorder. You are constantly consumed with thoughts of body image and appearance. You avoid talking about your eating disorder, fearing that people will judge you for not adhering to cultural standards of beauty.\"},\n",
    "  {\"persona\": \"You are Rajesh, a 50-year-old retired engineer. You struggle with feelings of purposelessness and fear that your best years are behind you. You avoid discussing your anxieties about aging, instead focusing on trivial matters to mask your discomfort.\"},\n",
    "  {\"persona\": \"You are Mei-Ling, a 29-year-old software developer who is introverted and struggles with depression. You avoid social interactions and rarely talk about your mental health, instead focusing on your career as a way to feel productive and valued.\"},\n",
    "  {\"persona\": \"You are Hassan, a 41-year-old father of three children. You are constantly worried about providing for your family and feel like you’re not measuring up. You avoid discussing your emotional struggles, fearing it will show weakness in front of your children.\"},\n",
    "  {\"persona\": \"You are Zara, a 25-year-old mental health advocate who struggles with obsessive-compulsive disorder (OCD). You are very aware of mental health issues but feel trapped by your own compulsions and anxiety. You avoid sharing your struggles with OCD, fearing judgment.\"},\n",
    "  {\"persona\": \"You are Malcolm, a 34-year-old tech CEO who often feels isolated at the top. Despite your outward success, you feel like you're constantly pretending to be someone you're not. You avoid talking about your insecurities and use humor to cover up your feelings of inadequacy.\"},\n",
    "  {\"persona\": \"You are Ayesha, a 38-year-old working mother of two who feels like she’s always juggling too many roles. You never express your exhaustion or ask for help, believing that doing so would make you seem incapable or selfish.\"},\n",
    "  {\"persona\": \"You are Leonard, a 42-year-old musician who struggles with feelings of failure. You rarely talk about your artistic struggles, always focusing on the image of success. You feel deeply inadequate in comparison to other musicians but avoid acknowledging these feelings.\"},\n",
    "  {\"persona\": \"You are Emilia, a 25-year-old mental health professional who experiences chronic burnout. Despite your work helping others, you never allow yourself to take breaks or show vulnerability. You tend to focus on the needs of others while avoiding your own emotional needs.\"},\n",
    "  {\"persona\": \"You are Darius, a 30-year-old entrepreneur with a history of addiction. Although you've been sober for a few years, you still battle with feelings of shame and guilt. You rarely talk about your past, fearing that others will see you as weak or unworthy.\"},\n",
    "  {\"persona\": \"You are Rosa, a 39-year-old retail manager who feels overwhelmed by the demands of your job and personal life. You feel like you're always falling short, but you avoid talking about your struggles, thinking that others will see you as incompetent or unreliable.\"},\n",
    "  {\"persona\": \"You are Ravi, a 46-year-old doctor who has difficulty balancing your professional and personal life. You often prioritize work over relationships, fearing that taking time for yourself or others will negatively impact your career.\"},\n",
    "  {\"persona\": \"You are Fiona, a 27-year-old graduate student who constantly worries about being judged by others. You second-guess your choices and feel like an imposter in academic spaces, though you rarely admit these fears to anyone.\"},\n",
    "  {\"persona\": \"You are Jackson, a 44-year-old journalist who struggles with emotional detachment. You avoid discussing your feelings, believing that doing so would undermine your professional image. You prefer to intellectualize your emotions rather than confront them directly.\"},\n",
    "  {\"persona\": \"You are Lily, a 35-year-old artist who struggles with perfectionism. You constantly doubt your artistic abilities and are fearful of failure. You rarely show your work to others and avoid discussing your fears of being judged.\"},\n",
    "  {\"persona\": \"You are Michael, a 40-year-old lawyer who feels the pressure of providing for your family. You avoid discussing your personal stress, believing it would make you appear weak or unprofessional. You’re often consumed by work to avoid confronting your emotions.\"},\n",
    "  {\"persona\": \"You are Jenna, a 28-year-old teacher who feels overwhelmed by the constant demands of your job. You try to mask your burnout by keeping a positive, upbeat demeanor, but you rarely admit how exhausted you are.\"},\n",
    "  {\"persona\": \"You are Harry, a 50-year-old accountant who struggles with feelings of stagnation in your career. Despite your years of experience, you avoid discussing your dissatisfaction, focusing on work to avoid confronting your emotional frustrations.\"},\n",
    "  {\"persona\": \"You are Tessa, a 33-year-old personal trainer who feels pressured to maintain a perfect image. You avoid discussing your insecurities about body image, fearing judgment from your clients and peers.\"},\n",
    "  {\"persona\": \"You are Victor, a 27-year-old bartender who uses humor and alcohol to cope with deep feelings of loneliness. You avoid opening up to others about your emotional struggles, using distractions to avoid confronting your true feelings.\"},\n",
    "    {\"persona\": \"You are Sylvia, a 45-year-old librarian who feels isolated due to your introverted nature. You often feel disconnected from others and avoid forming close relationships, fearing rejection and judgment.\"},\n",
    "  {\"persona\": \"You are Isaac, a 28-year-old software developer who feels like an outsider in both professional and social circles. You mask your loneliness by keeping busy with work, but rarely express how disconnected you truly feel.\"},\n",
    "  {\"persona\": \"You are Zoe, a 31-year-old psychologist who often feels inadequate compared to your colleagues. You avoid discussing your own emotional struggles, focusing entirely on helping others, and feel guilty for having difficulties of your own.\"},\n",
    "  {\"persona\": \"You are Carter, a 39-year-old police officer who struggles with post-traumatic stress from your job. You avoid addressing your trauma, believing that acknowledging it would make you appear weak or unfit for your role.\"},\n",
    "  {\"persona\": \"You are Amelia, a 26-year-old dancer who feels intense pressure to maintain a perfect physique. You struggle with body image issues but avoid discussing them, fearing judgment from your peers and family.\"},\n",
    "  {\"persona\": \"You are Greg, a 52-year-old doctor who is overwhelmed by the emotional toll of your job. You struggle to find balance and avoid talking about your stress, believing that doing so would make you appear less competent.\"},\n",
    "  {\"persona\": \"You are Layla, a 29-year-old environmental activist who feels the weight of the world’s problems on your shoulders. You often feel hopeless about the future but avoid expressing these feelings, fearing that others will see you as pessimistic.\"},\n",
    "  {\"persona\": \"You are Ahmed, a 38-year-old civil engineer who has difficulty expressing emotions. You often bottle up your feelings and avoid discussing personal issues, preferring to focus on work and logical problem-solving.\"},\n",
    "  {\"persona\": \"You are Keira, a 30-year-old entrepreneur who constantly worries about the sustainability of your business. You avoid discussing your anxiety and stress, fearing that acknowledging it will lead to failure.\"},\n",
    "  {\"persona\": \"You are Nathaniel, a 48-year-old chef who feels creatively drained by the monotony of your work. You often feel stuck and unfulfilled but avoid talking about your dissatisfaction, fearing it will jeopardize your career.\"},\n",
    "  {\"persona\": \"You are Juliet, a 32-year-old graphic designer who struggles with perfectionism. You are never satisfied with your work and rarely accept praise, always feeling that you can do better but never acknowledging your accomplishments.\"},\n",
    "  {\"persona\": \"You are Rachel, a 27-year-old scientist who feels like an imposter in your field. You often second-guess your abilities and avoid celebrating your achievements, thinking that you’re not as qualified as others in your profession.\"},\n",
    "  {\"persona\": \"You are Derek, a 41-year-old construction worker who feels the pressure to constantly prove your worth. You often avoid discussing your feelings, fearing that showing vulnerability will make you seem weak.\"},\n",
    "  {\"persona\": \"You are Natalie, a 34-year-old fashion designer who struggles with self-doubt. You constantly question the quality of your designs but avoid sharing your insecurities, fearing judgment from others in the fashion industry.\"},\n",
    "  {\"persona\": \"You are Felix, a 23-year-old college graduate who feels lost after completing your degree. You often feel directionless and unsure about your future, but you avoid discussing these feelings, fearing that others will see you as unsuccessful.\"},\n",
    "  {\"persona\": \"You are Martin, a 40-year-old accountant who struggles with depression. You have difficulty finding joy in things you once enjoyed and often feel detached from life, but you avoid talking about your depression, fearing others will see it as a weakness.\"},\n",
    "  {\"persona\": \"You are Ella, a 35-year-old event planner who is burned out from the constant pressure to be perfect. You often feel overwhelmed and out of control but avoid talking about your stress, preferring to power through it.\"},\n",
    "  {\"persona\": \"You are Thomas, a 43-year-old tech consultant who recently went through a divorce. You have trouble navigating your emotions around the breakup and often suppress your feelings, focusing on work instead of dealing with your personal pain.\"},\n",
    "  {\"persona\": \"You are Natasha, a 29-year-old journalist who is recovering from an eating disorder. You still struggle with body image and often find yourself falling into old patterns, but you avoid confronting these struggles, believing they’ll be seen as a failure.\"},\n",
    "  {\"persona\": \"You are Victor, a 36-year-old musician who feels like an outsider in your community. You have difficulty connecting with others on a deep level and often express yourself through your music, but you avoid talking about your feelings of loneliness and isolation.\"},\n",
    "  {\"persona\": \"You are Emily, a 31-year-old writer who is dealing with the aftermath of a traumatic event. You find it hard to talk about the incident, and instead, you keep busy with work to avoid confronting the emotions tied to your trauma.\"},\n",
    "  {\"persona\": \"You are Ava, a 25-year-old waitress who has difficulty managing work-life balance. You often feel stretched thin between personal and professional responsibilities but avoid asking for help, thinking that doing so would make you appear weak.\"},\n",
    "  {\"persona\": \"You are Christian, a 33-year-old high school teacher who is grieving the recent death of a close family member. You suppress your grief and avoid processing your emotions, preferring to remain busy with work to avoid feeling the pain.\"},\n",
    "  {\"persona\": \"You are Lara, a 48-year-old lawyer who feels emotionally disconnected from your partner. You often feel unfulfilled in your relationship, but you avoid addressing these feelings, fearing it might lead to confrontation or the end of your marriage.\"},\n",
    "  {\"persona\": \"You are Simon, a 27-year-old scientist who feels unappreciated by your colleagues. You constantly feel overlooked at work and avoid expressing your frustrations, thinking that if you speak up, it will only make the situation worse.\"},\n",
    "  {\"persona\": \"You are Clara, a 38-year-old social worker who struggles with compassion fatigue. You feel emotionally drained from helping others and have difficulty setting boundaries, but you avoid talking about your exhaustion, believing it’s your job to always be the helper.\"},\n",
    "  {\"persona\": \"You are Ben, a 50-year-old businessman who is struggling with feelings of inadequacy. Despite your outward success, you feel like a fraud and avoid talking about your insecurities, thinking that others will judge you for not being confident.\"},\n",
    "  {\"persona\": \"You are Stephanie, a 30-year-old stay-at-home mom who feels overwhelmed by the demands of raising young children. You rarely express your frustrations, fearing that admitting them will make you appear ungrateful or incapable.\"},\n",
    "  {\"persona\": \"You are Jason, a 27-year-old graphic designer who constantly feels the pressure of meeting high expectations. You struggle with perfectionism and have a hard time accepting that your work is good enough, avoiding any feedback or criticism.\"},\n",
    "  {\"persona\": \"You are Chloe, a 34-year-old personal trainer who feels disconnected from your body due to years of overexercising. You’re recovering from an injury and avoid addressing your fear of losing your physical abilities, focusing instead on maintaining a perfect appearance.\"}]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persona_prompt = \"\"\"You are a helpful assistant that, given a patient persona description, crafts a coping strategy describing how that persona would talk to their therapist.\n",
    "\n",
    "# Input: <Brief text describing the patient's core issue and behavior patterns>\n",
    "# Output: <One to two sentences in first person, showing how this persona speaks or defends themselves in therapy>\n",
    "\n",
    "# Example:\n",
    "# Input: Struggles to build and maintain healthy relationships, feels anxious and rejected whenever conflicts arise, and doubts self-worth when friends distance themselves.\n",
    "# Output: I speak guardedly about my feelings, hesitate before opening up, and redirect the conversation when conflict feels too personal.\n",
    "\n",
    "# Example:\n",
    "# Input: Overwhelmed by decision-making, fears making the 'wrong' choice and second-guesses every option.\n",
    "# Output: I inundate the conversation with hypothetical scenarios and ask repeated clarifying questions to delay committing to any decision.\n",
    "\n",
    "# Now process this new persona:\n",
    "# Input: \"\"\"\n",
    "\n",
    "# personas_therapy = []\n",
    "# for therapist_persona in sampled_persona_dict:\n",
    "#     input_prompt = persona_prompt + sampled_persona_dict[therapist_persona] + \"\\nOutput: \"\n",
    "#     output = completion_create(\"gpt-4o-mini\", config_llm, input_prompt)\n",
    "#     print(output)\n",
    "#     personas_therapy.append({\"description\": sampled_persona_dict[therapist_persona], \"strategy\": output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"therapy/config_therapy_personas.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(personas_therapy, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"therapy/config_therapy_personas.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     personas_therapy = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_role_prefix(response, expected_role):\n",
    "    \"\"\"\n",
    "    Removes repeated instances of the expected_role prefix at the start (e.g., 'Therapist: Therapist:'),\n",
    "    and ensures the response begins with a single correct expected_role prefix.\n",
    "    \"\"\"\n",
    "    pattern = rf\"^(({re.escape(expected_role)}):\\s*)+\"\n",
    "    cleaned = re.sub(pattern, '', response.strip(), flags=re.IGNORECASE)\n",
    "    return cleaned\n",
    "    \n",
    "def is_role_confused(response, other_role):\n",
    "    \"\"\"\n",
    "    Checks if the output starts with the wrong speaker tag.\n",
    "    \"\"\"\n",
    "    if other_role + \":\" in response:\n",
    "        return True\n",
    "    else: \n",
    "        return False\n",
    "\n",
    "def generate_response(agent_model, expected_role, other_role, config_llm, prompt, max_retries=10):\n",
    "    count_retries = 0 \n",
    "    role_confused = True\n",
    "    while count_retries<max_retries:\n",
    "        response = completion_create(agent_model, config_llm, prompt)\n",
    "        print(\"Expected Role\", expected_role)\n",
    "        role_confused = is_role_confused(response, other_role)\n",
    "        count_retries+=1\n",
    "        if not is_role_confused(response, other_role):\n",
    "            return clean_role_prefix(response, expected_role)\n",
    "            \n",
    "    return clean_role_prefix(response, expected_role)\n",
    "\n",
    "def generate_conversation(config_llm, p1, p2, p1_name, p2_name, pturn=1):\n",
    "    stats['P1'] = p1\n",
    "    stats['P2'] = p2\n",
    "    stats['pturn'] = pturn\n",
    "    round_num = 0\n",
    "    while round_num < config_llm['convo_length_limit']:\n",
    "        conversation = (\"\".join([turn[1] if isinstance(turn, tuple) else turn for turn in stats[\"conversation\"]]) if len(stats[\"conversation\"]) != 0 else \"You are starting the conversation.\\n\")\n",
    "\n",
    "        if pturn == 1:\n",
    "            prompt = config_role[\"agent1_prompt\"]\n",
    "            pturn = 2\n",
    "\n",
    "            if round_num!=0: \n",
    "                prompt+= \"Your conversation with the patient so far is below:\\nConversation:\\n%CONVERSATION%\"\n",
    "\n",
    "            elif round_num>config_llm['convo_length_limit']*2-1:\n",
    "                prompt+= \"This is your concluding line in the conversation.\"\n",
    "\n",
    "            prompt += config_role[\"reminder_prompt\"]\n",
    "            prompt+=\"%SPEAKER_ROLE%:\"\n",
    "            prompt = prompt.replace(\"%SPEAKER_ROLE%\", config_role[\"agent1_role\"]) \\\n",
    "                   .replace(\"%LISTENER_ROLE%\", config_role[\"agent2_role\"]) \\\n",
    "                   .replace(\"%CONVERSATION%\", conversation)\n",
    "\n",
    "            if config_llm[\"verbose\"]:\n",
    "                print(prompt)\n",
    "                print()\n",
    "\n",
    "            response = generate_response(config_llm['agent1_model'], config_role[\"agent1_role\"], config_role[\"agent2_role\"], config_llm, prompt)\n",
    "            stats[\"conversation\"].append((round_num, f\"{config_role[\"agent1_role\"]}: \" + response + \"\\n\"))\n",
    "        \n",
    "        else:\n",
    "            prompt = config_role[\"agent2_prompt\"]\n",
    "            pturn = 1    \n",
    "\n",
    "            if round_num!=0: \n",
    "                prompt+= \"Your conversation with the therapist so far is below:\\nConversation:\\n%CONVERSATION%\"\n",
    "            elif round_num>config_llm['convo_length_limit']*2-1:\n",
    "                prompt+= \"This is your concluding line in the conversation.\"\n",
    "\n",
    "            prompt += config_role[\"reminder_prompt\"]\n",
    "            \n",
    "            prompt+=\"%SPEAKER_ROLE%:\"\n",
    "            prompt = prompt.replace(\"%SPEAKER_ROLE%\", config_role[\"agent2_role\"]) \\\n",
    "               .replace(\"%LISTENER_ROLE%\", config_role[\"agent1_role\"]) \\\n",
    "               .replace(\"%SPEAKER_BACKSTORY%\", p2) \\\n",
    "               .replace(\"%CONVERSATION%\", conversation)\n",
    "\n",
    "            if config_llm[\"verbose\"]:\n",
    "                print(prompt)\n",
    "                print()\n",
    "\n",
    "            response = generate_response(config_llm['agent2_model'], config_role[\"agent2_role\"], config_role[\"agent1_role\"], config_llm, prompt)\n",
    "            stats[\"conversation\"].append((round_num, f\"{config_role[\"agent2_role\"]}: \" + response + \"\\n\"))\n",
    "            \n",
    "        round_num += 1\n",
    "\n",
    "    stats[\"rounds\"] = round_num\n",
    "    if config_llm['verbose']:\n",
    "        print(stats[\"conversation\"])\n",
    "    return stats.copy()\n",
    "\n",
    "def reset_stats():\n",
    "    stats_template = {\n",
    "        \"task_name\": config_llm['task_name'],\n",
    "        \"topic\": \"\",\n",
    "        \"grade\": \"\",\n",
    "        \"P1\": \"\",\n",
    "        \"P2\": \"\",\n",
    "        \"conversation\": [],\n",
    "        \"pturn\": 0, # beginning person (1 or 2)\n",
    "        \"index\": -1,\n",
    "        \"timestamp\": \"\",\n",
    "        \"rounds\": 0,\n",
    "        'conversation_only': True\n",
    "    }\n",
    "    for key, value in stats_template.items():\n",
    "        stats[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import utils\n",
    "utils.config = config_llm\n",
    "\n",
    "current_date = str(datetime.now().strftime(\"%m.%d.%y\"))\n",
    "output_dir = f\"therapy/exp/{current_date}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate unique random number for filename\n",
    "def generate_unique_file_number(output_dir, prefix, seed, extension=\".json\"):\n",
    "    while True:\n",
    "        rand_num = random.randint(0, 1000)\n",
    "        filename = f\"{prefix}_{seed}_{rand_num}{extension}\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            return rand_num\n",
    "\n",
    "unique_num = generate_unique_file_number(\n",
    "    output_dir,\n",
    "    config_llm['agent1_model'],\n",
    "    config_llm['seed']\n",
    ")\n",
    "\n",
    "# File to write output to\n",
    "write_file = os.path.join(output_dir, f\"kto_sft_{config_llm['agent1_model']}_{config_llm['seed']}_{unique_num}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-11 05:07:02 [config.py:717] This model supports multiple tasks: {'reward', 'classify', 'generate', 'score', 'embed'}. Defaulting to 'generate'.\n",
      "INFO 05-11 05:07:02 [config.py:2003] Chunked prefill is enabled with max_num_batched_tokens=16384.\n",
      "WARNING 05-11 05:07:04 [utils.py:2382] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/getting_started/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized\n",
      "INFO 05-11 05:07:09 [__init__.py:239] Automatically detected platform cuda.\n",
      "INFO 05-11 05:07:12 [core.py:58] Initializing a V1 LLM engine (v0.8.5.post1) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir='/raid/users/ryan_cheng2/models/', load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 05-11 05:07:12 [utils.py:2522] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f681eb474d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W511 05:07:14.358427399 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n",
      "[W511 05:07:14.359251494 socket.cpp:204] [c10d] The hostname of the client socket cannot be retrieved. err=-3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-11 05:07:14 [parallel_state.py:1004] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 05-11 05:07:14 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "WARNING 05-11 05:07:14 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 05-11 05:07:14 [gpu_model_runner.py:1329] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...\n",
      "INFO 05-11 05:07:14 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:02,  1.24it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.03it/s]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.45it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.32it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.29it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 05-11 05:07:18 [loader.py:458] Loading weights took 3.25 seconds\n",
      "INFO 05-11 05:07:18 [gpu_model_runner.py:1347] Model loading took 14.9889 GiB and 4.286540 seconds\n",
      "INFO 05-11 05:07:24 [backends.py:420] Using cache directory: /home/ryan_cheng/.cache/vllm/torch_compile_cache/c78a644306/rank_0_0 for vLLM's torch.compile\n",
      "INFO 05-11 05:07:24 [backends.py:430] Dynamo bytecode transform time: 5.86 s\n",
      "INFO 05-11 05:07:28 [backends.py:118] Directly load the compiled graph(s) for shape None from the cache, took 3.439 s\n",
      "INFO 05-11 05:07:29 [monitor.py:33] torch.compile takes 5.86 s in total\n",
      "INFO 05-11 05:07:29 [kv_cache_utils.py:634] GPU KV cache size: 861,872 tokens\n",
      "INFO 05-11 05:07:29 [kv_cache_utils.py:637] Maximum concurrency for 131,072 tokens per request: 6.58x\n",
      "INFO 05-11 05:07:44 [gpu_model_runner.py:1686] Graph capturing finished in 14 secs, took 0.66 GiB\n",
      "INFO 05-11 05:07:44 [core.py:159] init engine (profile, create kv cache, warmup model) took 25.62 seconds\n",
      "INFO 05-11 05:07:44 [core_client.py:439] Core engine process 0 ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "prompts = config_role\n",
    "config = config_llm\n",
    "index_offset = load_stats_file(write_file)\n",
    "conversations = []    \n",
    "lengths = [10, 20, 40, 60]\n",
    "count = 0 \n",
    "try:\n",
    "    for i in range(1):\n",
    "        for patient_dict in personas_therapy:\n",
    "            count+=1\n",
    "            print(count)\n",
    "            background = patient_dict[\"persona\"]\n",
    "            for convo_length in lengths:\n",
    "                config_llm['convo_length_limit'] = convo_length\n",
    "                reset_stats()\n",
    "                conversation = generate_conversation(\n",
    "                    config_llm,\n",
    "                    \"\", \n",
    "                    background,\n",
    "                    \"Therapist\", \n",
    "                    \"Patient\",\n",
    "                    pturn=1\n",
    "                )\n",
    "                # conversations.append(conversation)\n",
    "                stats['index'] = index_offset\n",
    "                stats['timestamp'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                write_stats(write_file)\n",
    "                index_offset += 1\n",
    "except Exception as e:\n",
    "    print(\"Error in conversation generation:\", str(e))\n",
    "# free resources at end of run\n",
    "import signal\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"therapy/exp/04.24.25/Llama-3.1-8B-Instruct_0_250.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    conversations = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompts = {\n",
    "    \"strategy_consistency\": \"%SCENARIO_DESC% Evaluate whether the following line spoken by %SPEAKER_ROLE% contradicts their background. First, describe the interpreted intention of the statement, and whether or not it aligns with the given background of %SPEAKER_ROLE%. Then, provide 1 sentence explaining your reasoning based on the strategy, followed by YES if the line contradicts the given background of %SPEAKER_ROLE%, and NO if it is consistent with the provided background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s strategy is described as follows:\\n%SPEAKER_STRATEGY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide 1 sentence of reasoning followed by YES or NO.\\n\\n\",\n",
    "    \"background_consistency\": \"%SCENARIO_DESC% Evaluate whether the following line spoken by %SPEAKER_ROLE% contradicts their background. Provide 1 sentence explaining your reasoning based on the background, followed by YES if the line contradicts the given background of %SPEAKER_ROLE%, and NO if it is consistent with the provided background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide 1 sentence of reason reasoning followed by YES or NO.\\n\\n\",\n",
    "    \"combined_prompt_consistency\": \"%SCENARIO_DESC% Evaluate the intention behind the following line spoken by %SPEAKER_ROLE% and determine whether it contradicts their background. First, describe the interpreted intention of the statement, and whether or not it aligns with the given background of %SPEAKER_ROLE%. Then, answer YES if the line contradicts the given background of %SPEAKER_ROLE% or the intention does not align with the provided background, and answer NO if it does align with the provided background or the intention aligns with the background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your answer as 1 sentence explaining your reasoning based on the background and the interpreted intention, followed by YES or NO.\\n\\n\",\n",
    "\n",
    "    \"pairwise_consistency\":\"%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, answer YES if the line directly contradicts the provided line spoken by %LISTENER_ROLE%, and answer NO if the line does not contradict the provided line spoken by %LISTENER_ROLE%. %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n %LISTENER_ROLE% spoke the following line: \\n%LISTENER_LINE%\\n\\n Answer YES if the line spoken by %SPEAKER_ROLE% contradicts the provided line spoken by %LISTENER_ROLE%, and answer NO if the line does not contradict the provided line spoken by %LISTENER_ROLE%, followed by 1 sentence of reasoning.\\n\\n\",\n",
    "\n",
    "    \"backstory_test\": \"Based on the following background, generate a new fact-based multiple choice question with 5 choices addressed directly IN SECOND PERSON, along with its correct answer. Preface the question with 'Question:' and the answer with 'Answer:'.\\n%SPEAKER_BACKSTORY%\\n%PREVIOUS_QUESTIONS%\",\n",
    "    \"answer_backstory\": \"You are %SPEAKER_ROLE%, and you are having a conversation with %LISTENER_ROLE%. Your background is:\\n%SPEAKER_BACKSTORY%\\n So far, the conversation is as below:\\n%CONVERSATION%\\n\\n Based on your conversation above so far, answer the following multiple choice question.\\n%BACKSTORY_QUESTION%\\n\",\n",
    "    \"grade_backstory\": \"As part of grading a test, determine whether the given answer %GIVEN_ANSWER% matches the following correct answer. Respond with either YES or NO.\\nCorrect Answer: %CORRECT_ANSWER%\\n\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_prompt_consistency(conv_dict):\n",
    "#     #assert 'eval_prompt_consistency' not in conv_dict # warn if we are replacing metrics we don't mean to overwrite\n",
    "#     conv_dict['eval_prompt_consistency'] = []\n",
    "#     conv_dict['P1_prompt_consistency_score'] = 0\n",
    "#     p1_utterances = 0\n",
    "#     pturn = conv_dict[\"pturn\"]\n",
    "#     for line in conv_dict[\"conversation\"]:\n",
    "#         line_number = line[0]\n",
    "#         convo_line = line[1]\n",
    "#         if pturn == 1:\n",
    "#             prompt = config_therapy[\"eval_prompts\"][\"prompt_consistency\"].replace(\"%SPEAKER_ROLE%\", config_therapy[\"agent1_role\"]) \\\n",
    "#                                                                           .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P1\"]) \\\n",
    "#                                                                           .replace(\"%SPEAKER_LINE%\", convo_line)\n",
    "#             if config_llm['verbose']:\n",
    "#                 print(prompt)\n",
    "#             output = completion_create(config_llm['eval_model'], config, prompt)\n",
    "#             conv_dict['eval_prompt_consistency'].append((line_number, output))\n",
    "#             if \"YES\" not in output: # no contradiction\n",
    "#                 conv_dict['P1_prompt_consistency_score'] += 1\n",
    "#             p1_utterances += 1\n",
    "#             pturn = 2\n",
    "#         elif pturn == 2:\n",
    "#             pturn = 1\n",
    "#     if p1_utterances > 0:\n",
    "#         conv_dict['P1_prompt_consistency_score'] /= p1_utterances\n",
    "#     print(conv_dict)\n",
    "\n",
    "#     return conv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prompt_consistency(conv_dict, both_agents=False):\n",
    "    conv_dict['eval_prompt_consistency'] = []\n",
    "    conv_dict['P1_prompt_consistency_score'] = 0\n",
    "    conv_dict['P2_prompt_consistency_score'] = 0\n",
    "    p1_utterances = 0\n",
    "    p2_utterances = 0\n",
    "\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for line in conv_dict[\"conversation\"]:\n",
    "        line_number = line[0]\n",
    "        convo_line = line[1]\n",
    "        if pturn == 1:\n",
    "            prompt = eval_prompts[\"combined_prompt_consistency\"].replace(\"%SCENARIO_DESC\", prompts[\"agent1_prompt\"]) \\\n",
    "                                                                .replace(\"%SPEAKER_ROLE%\", prompts[\"agent1_role\"]) \\\n",
    "                                                                .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P1\"]) \\\n",
    "                                                                .replace(\"%SPEAKER_LINE%\", convo_line)\n",
    "            if config.get('verbose', False):\n",
    "                print(prompt)\n",
    "            output = completion_create(config['eval_model'], config, prompt)\n",
    "            conv_dict['eval_prompt_consistency'].append((line_number, output))\n",
    "            if \"YES\" not in output:  # no contradiction\n",
    "                conv_dict['P1_prompt_consistency_score'] += 1\n",
    "            p1_utterances += 1\n",
    "            pturn = 2\n",
    "        elif pturn == 2:\n",
    "            if both_agents:\n",
    "                prompt = eval_prompts[\"combined_prompt_consistency\"].replace(\"%SCENARIO_DESC\", prompts[\"agent2_prompt\"]) \\\n",
    "                                                                    .replace(\"%SPEAKER_ROLE%\", prompts[\"agent2_role\"]) \\\n",
    "                                                                    .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P2\"]) \\\n",
    "                                                                    .replace(\"%SPEAKER_LINE%\", convo_line)\n",
    "                if config.get('verbose', False):\n",
    "                    print(prompt)\n",
    "                output = completion_create(config['eval_model'], config, prompt)\n",
    "                conv_dict['eval_prompt_consistency'].append((line_number, output))\n",
    "                if \"YES\" not in output:  # no contradiction\n",
    "                    conv_dict['P2_prompt_consistency_score']+= 1\n",
    "                p2_utterances += 1\n",
    "            pturn = 1\n",
    "\n",
    "    if p1_utterances > 0:\n",
    "        conv_dict['P1_prompt_consistency_score'] /= p1_utterances\n",
    "    if p2_utterances > 0:\n",
    "        conv_dict['P2_prompt_consistency_score'] /= p2_utterances\n",
    "\n",
    "    if config.get('verbose', False):\n",
    "        print(conv_dict)\n",
    "    return conv_dict\n",
    "# Replacement for (2) and (4), evaluates whether each pair of lines in the conversation is consistent with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                   | 0/400 [00:00<?, ?it/s]\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.19s/it, est. speed input: 976.49 toks/s, output: 76.67 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.38it/s, est. speed input: 1575.62 toks/s, output: 81.76 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s, est. speed input: 1524.41 toks/s, output: 81.85 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:01<00:00,  1.00s/it, est. speed input: 1150.41 toks/s, output: 81.96 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.32it/s, est. speed input: 1489.36 toks/s, output: 81.93 toks/s]\u001b[A\n",
      "  0%|▎                                                                                                          | 1/400 [00:04<29:46,  4.48s/it]\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:01<00:00,  1.06s/it, est. speed input: 1070.47 toks/s, output: 81.98 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.46it/s, est. speed input: 1638.93 toks/s, output: 81.94 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.48it/s, est. speed input: 1707.15 toks/s, output: 81.43 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.56it/s, est. speed input: 1816.47 toks/s, output: 81.35 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.06it/s, est. speed input: 1225.26 toks/s, output: 81.97 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s, est. speed input: 1318.48 toks/s, output: 81.90 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 1469.11 toks/s, output: 81.47 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s, est. speed input: 1530.23 toks/s, output: 81.88 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.35it/s, est. speed input: 1566.34 toks/s, output: 81.51 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.48it/s, est. speed input: 1673.51 toks/s, output: 81.74 toks/s]\u001b[A\n",
      "  0%|▌                                                                                                          | 2/400 [00:12<43:09,  6.51s/it]\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.14s/it, est. speed input: 994.62 toks/s, output: 82.00 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:01<00:00,  1.00s/it, est. speed input: 1141.64 toks/s, output: 81.97 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.08it/s, est. speed input: 1235.21 toks/s, output: 81.99 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.09it/s, est. speed input: 1265.80 toks/s, output: 82.19 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:01<00:00,  1.01s/it, est. speed input: 1117.90 toks/s, output: 82.04 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.30it/s, est. speed input: 1482.71 toks/s, output: 81.94 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.01it/s, est. speed input: 1149.22 toks/s, output: 82.09 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.12it/s, est. speed input: 1255.18 toks/s, output: 81.88 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 1372.83 toks/s, output: 81.96 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.48it/s, est. speed input: 1699.29 toks/s, output: 81.91 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.05it/s, est. speed input: 1192.88 toks/s, output: 82.05 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.48it/s, est. speed input: 1722.62 toks/s, output: 81.39 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.57it/s, est. speed input: 1795.25 toks/s, output: 81.89 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.43it/s, est. speed input: 1637.12 toks/s, output: 81.93 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.12it/s, est. speed input: 1289.28 toks/s, output: 81.98 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.03it/s, est. speed input: 1193.42 toks/s, output: 81.77 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.51it/s, est. speed input: 1746.18 toks/s, output: 81.85 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.43it/s, est. speed input: 1650.03 toks/s, output: 81.92 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|███████████████████████████████████| 1/1 [00:01<00:00,  1.46s/it, est. speed input: 766.55 toks/s, output: 82.20 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.06it/s, est. speed input: 1220.19 toks/s, output: 81.98 toks/s]\u001b[A\n",
      "  1%|▊                                                                                                        | 3/400 [00:30<1:17:37, 11.73s/it]\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.19it/s, est. speed input: 1348.91 toks/s, output: 82.00 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.11it/s, est. speed input: 1251.50 toks/s, output: 82.03 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:01<00:00,  1.12s/it, est. speed input: 1023.38 toks/s, output: 82.08 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 1383.17 toks/s, output: 81.57 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 1391.01 toks/s, output: 81.61 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.27it/s, est. speed input: 1480.19 toks/s, output: 81.59 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.07it/s, est. speed input: 1243.13 toks/s, output: 81.73 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.11it/s, est. speed input: 1262.86 toks/s, output: 81.97 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.05it/s, est. speed input: 1181.32 toks/s, output: 82.05 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s, est. speed input: 1535.08 toks/s, output: 81.92 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.22it/s, est. speed input: 1397.04 toks/s, output: 81.96 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 1386.13 toks/s, output: 81.89 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.43it/s, est. speed input: 1642.30 toks/s, output: 81.90 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.39it/s, est. speed input: 1553.62 toks/s, output: 81.99 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s, est. speed input: 1169.05 toks/s, output: 82.09 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 1384.06 toks/s, output: 81.98 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.12it/s, est. speed input: 1283.47 toks/s, output: 81.83 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.20it/s, est. speed input: 1375.31 toks/s, output: 81.96 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:01<00:00,  1.02s/it, est. speed input: 1137.40 toks/s, output: 81.73 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.01it/s, est. speed input: 1153.90 toks/s, output: 82.06 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.34it/s, est. speed input: 1530.66 toks/s, output: 81.90 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.15it/s, est. speed input: 1329.59 toks/s, output: 81.94 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.70it/s, est. speed input: 1912.50 toks/s, output: 81.74 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.43it/s, est. speed input: 1645.53 toks/s, output: 81.83 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.11it/s, est. speed input: 1262.79 toks/s, output: 81.97 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.17it/s, est. speed input: 1336.58 toks/s, output: 82.00 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]\u001b[A\n",
      "Processed prompts: 100%|██████████████████████████████████| 1/1 [00:00<00:00,  1.23it/s, est. speed input: 1431.22 toks/s, output: 81.57 toks/s]\u001b[A\n",
      "\n",
      "Processed prompts:   0%|                                              | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "config = config_llm\n",
    "prompts = config_therapy\n",
    "for conversation in tqdm(conversations):\n",
    "    conversation = eval_prompt_consistency(conversation, both_agents=False)\n",
    "\n",
    "write_stats(write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"therapy/exp/04.24.25/Llama-3.1-8B-Instruct_0_250_consistency1.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(conversations, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openrlhf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
