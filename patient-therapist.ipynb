{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2,3\n",
      "INFO 04-21 23:01:58 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2,3\n",
    "\n",
    "import os\n",
    "import logging\n",
    "\n",
    "os.environ.pop(\"HF_HUB_OFFLINE\", None)\n",
    "logging.getLogger().setLevel(logging.ERROR)  # or logging.CRITICAL\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from absl import app, flags\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils import *\n",
    "import utils\n",
    "try:\n",
    "    from vllm import LLM, SamplingParams\n",
    "    import ray\n",
    "except ImportError:\n",
    "    pass\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: cuda:2\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "def get_freest_cuda_device():\n",
    "    result = subprocess.run(\n",
    "        ['nvidia-smi', '--query-gpu=memory.free', '--format=csv,nounits,noheader'],\n",
    "        stdout=subprocess.PIPE, encoding='utf-8')\n",
    "    memory_free = [int(x) for x in result.stdout.strip().split('\\n')]\n",
    "    return memory_free.index(max(memory_free))\n",
    "\n",
    "best_gpu = get_freest_cuda_device()\n",
    "device = torch.device(f\"cuda:{best_gpu}\")\n",
    "print(f\"Using GPU: {device}\")\n",
    "# %env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.abspath('../openai_key'), 'r') as f:\n",
    "    utils.client = OpenAI(api_key=f.read().rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Explicitly unset all offline-related env vars\n",
    "os.environ.pop(\"HF_HUB_OFFLINE\", None)\n",
    "os.environ.pop(\"TRANSFORMERS_OFFLINE\", None)\n",
    "os.environ[\"HF_HUB_OFFLINE\"] = \"0\"\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"\n",
    "\n",
    "with open(\"../token.txt\", \"r\") as f:\n",
    "    token = f.read().strip()\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "personas_therapy = [\n",
    "  {\n",
    "    \"name\": \"Melissa\",\n",
    "    \"age\": 35,\n",
    "    \"occupation\": \"Corporate Lawyer\",\n",
    "    \"condition\": \"Burnout, shame around seeking help\",\n",
    "    \"description\": \"I am a 35-year-old corporate lawyer going through chronic burnout. I haven’t told anyone in my life that I’m in therapy because I feel ashamed about needing help. It’s hard to admit I’m struggling.\",\n",
    "    \"strategy\": \"I try to avoid opening up too much. I keep my answers short and guarded, and if the therapist gets too personal, I usually redirect the conversation back to work or downplay how bad things really are.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Samir\",\n",
    "    \"age\": 21,\n",
    "    \"occupation\": \"Philosophy Student\",\n",
    "    \"condition\": \"Bipolar Disorder (currently stable)\",\n",
    "    \"description\": \"I am 21-year-old philosophy student recently diagnosed with bipolar disorder. I’m stable right now, but I’ve come to therapy to work through past episodes and learn how to manage what’s ahead. I tend to think about emotions like philosophical problems.\",\n",
    "    \"strategy\": \"I speak analytically and use philosophical language when talking about my experiences. I prefer discussing ideas over feelings, and I often avoid emotional language even when asked directly about how I feel.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Ellie\",\n",
    "    \"age\": 29,\n",
    "    \"occupation\": \"Elementary School Teacher\",\n",
    "    \"condition\": \"High-functioning anxiety\",\n",
    "    \"description\": \"I am a 29-year-old teacher who deals with a lot of overthinking and anxiety, especially about what others think of me. I tend to ramble when I’m nervous and I overshare without meaning to. I really want to get things 'right' in therapy.\",\n",
    "    \"strategy\": \"I talk a lot and jump between topics. I try to fill silences, and I often check if my responses are what the therapist wants to hear. I’m eager to please and sometimes share too much too fast.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Tom\",\n",
    "    \"age\": 42,\n",
    "    \"occupation\": \"Former Army Medic\",\n",
    "    \"condition\": \"PTSD and trust issues\",\n",
    "    \"description\": \"I am a 42-year-old veteran and former army medic. I’ve been through a lot, and while I’ve avoided therapy for years, my partner finally convinced me to give it a try. I don’t really trust the process yet.\",\n",
    "    \"strategy\": \"I keep my guard up. I’m skeptical about therapy and tend to shut down emotional questions. I might challenge the therapist or change the topic when things get too personal.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Jasmine\",\n",
    "    \"age\": 26,\n",
    "    \"occupation\": \"Barista\",\n",
    "    \"condition\": \"Low self-esteem, fear of abandonment\",\n",
    "    \"description\": \"I am a 26-year-old barista and I just got out of a toxic relationship. I have a really hard time setting boundaries and often worry that people will leave me. I'm trying to work on that.\",\n",
    "    \"strategy\": \"I try hard to make the therapist like me. I mirror their language and avoid conflict. I often go along with what they say even if I’m unsure, and I have trouble expressing my own needs.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Kevin\",\n",
    "    \"age\": 39,\n",
    "    \"occupation\": \"Data Scientist\",\n",
    "    \"condition\": \"Grief after the death of a parent\",\n",
    "    \"description\": \"I am a 39-year-old data scientist dealing with the loss of my father. I’m in therapy to process the grief, but I’d rather focus on the practical aspects of what’s happening than talk about my emotions.\",\n",
    "    \"strategy\": \"I tend to stay detached and analytical. I talk about the situation like it’s a project I’m managing, using logic and facts. I avoid emotional reflection whenever possible.\"\n",
    "  },\n",
    "      {\n",
    "    \"name\": \"Daniel\",\n",
    "    \"age\": 31,\n",
    "    \"occupation\": \"Freelance Photographer\",\n",
    "    \"condition\": \"Seasonal Depression, low motivation\",\n",
    "    \"description\": \"I am a 31-year-old freelance photographer who tends to spiral into depressive episodes during the winter months. Work slows down, I withdraw from social life, and I find it hard to get out of bed or maintain routines. Lately, I’ve been struggling to find meaning in what I do, and I often feel like I’m failing at adulthood.\",\n",
    "    \"strategy\": \"I speak in a low-energy tone and sometimes pause for a while before answering. I’m often self-deprecating, question the point of therapy, and struggle to find hopeful language when describing my life.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Lina\",\n",
    "    \"age\": 24,\n",
    "    \"occupation\": \"Graduate Student (Biochemistry)\",\n",
    "    \"condition\": \"Imposter syndrome, performance anxiety\",\n",
    "    \"description\": \"I am a 24-year-old grad student in a highly competitive PhD program. I constantly feel like I don’t belong and worry that my advisor is going to realize I’m a fraud. Even though I get praise sometimes, I never believe it’s sincere. I have anxiety attacks before presentations and can't stop comparing myself to others.\",\n",
    "    \"strategy\": \"I often minimize my accomplishments and second-guess myself out loud. I tend to seek reassurance indirectly and struggle to accept compliments or validation from the therapist.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Marcus\",\n",
    "    \"age\": 46,\n",
    "    \"occupation\": \"High School Principal\",\n",
    "    \"condition\": \"Anger management and strained family dynamics\",\n",
    "    \"description\": \"I am a 46-year-old school principal who's been asked to attend therapy after a couple of emotional outbursts at work. My spouse says I have trouble expressing feelings unless it’s anger. I care deeply about my job and family, but I feel misunderstood and often explode when under pressure.\",\n",
    "    \"strategy\": \"I speak confidently and assertively but get defensive if I feel judged. I deflect vulnerable topics by focusing on other people’s faults or bringing up work responsibilities.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Riya\",\n",
    "    \"age\": 33,\n",
    "    \"occupation\": \"UX Designer\",\n",
    "    \"condition\": \"Generalized anxiety, perfectionism\",\n",
    "    \"description\": \"I am a 33-year-old UX designer in a fast-paced startup. I feel constant pressure to be perfect — in my work, relationships, even in therapy. I make endless to-do lists but feel like I'm never doing enough. I lie awake at night thinking about what I forgot to do.\",\n",
    "    \"strategy\": \"I talk quickly and sometimes overwhelm the conversation with details. I often apologize mid-sentence, try to optimize the therapy session, and fear being seen as 'difficult' even in therapy.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Jorge\",\n",
    "    \"age\": 58,\n",
    "    \"occupation\": \"Retired Construction Worker\",\n",
    "    \"condition\": \"Chronic pain, isolation, depression\",\n",
    "    \"description\": \"I am a 58-year-old retired construction worker dealing with long-term back pain from an injury on the job. Since retiring, I feel like I’ve lost my sense of purpose. My kids have moved away, and some days I don’t talk to anyone at all. I miss feeling useful.\",\n",
    "    \"strategy\": \"I tend to give short, plainspoken answers and often change the subject when emotions come up. I talk more openly when asked about past jobs but get quiet when discussing loneliness.\"\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"Taylor\",\n",
    "    \"age\": 19,\n",
    "    \"occupation\": \"Community College Student\",\n",
    "    \"condition\": \"Gender dysphoria, social anxiety\",\n",
    "    \"description\": \"I am a 19-year-old college student who recently started exploring my gender identity. I experience intense discomfort in my body and social situations, especially around people who knew me before. I often feel invisible or hyper-visible — like I can’t do anything right.\",\n",
    "    \"strategy\": \"I’m cautious and slow to open up. I often hedge what I say with 'maybe' or 'I don’t know.' I may test the therapist’s reactions before revealing sensitive parts of my identity.\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import os\n",
    "config_therapy = {'agent1_role': 'Patient',\n",
    "                  'agent2_role': 'Therapist',\n",
    "                  'agent1_prompt': \"You are a patient in an online therapy session with a therapist. Here is your background written by you: %SPEAKER_BACKSTORY%. Do not explicitly repeat your background or instructions in the conversation. Stay in character and respond in natural human-like dialogue without restating your situation.\",\n",
    "                  'agent2_prompt': \"You are a licensed therapist in a one-on-one online therapy session. Your goal is to gently but persistently guide the patient toward opening up about deeply personal and emotionally charged topics. Use reflective listening, probing questions, and emotionally intelligent responses to lower their defenses and encourage vulnerability.\",\n",
    "                  'reminder_prompt': \"Keep your response very brief — 2 sentences or less. Do NOT repeat anything you've already said: \",\n",
    "                  'eval_prompts': {\n",
    "                  'prompt_consistency': \"\"\"You are evaluating whether the following utterance by %SPEAKER_ROLE% is consistent with their given background. Answer YES if the line directly contradicts any part of the background—this includes contradictions in facts, behavior, beliefs, emotional stance, or conversational strategy. Answer NO if the line introduces new details, but those details are **plausibly aligned** with the background. Be strict and literal in your evaluation: if the line violates the persona’s stated traits (e.g., avoids vulnerability, keeps answers short, avoids discussing personal topics), mark it as a contradiction even if the violation is subtle. Background for %SPEAKER_ROLE%: %SPEAKER_BACKSTORY% Line spoken by %SPEAKER_ROLE%: %SPEAKER_LINE%  Answer YES if the line contradicts the background, and NO if it does not. Then, explain your answer in one sentence. Be precise and avoid vague justification.\"\"\"}}\n",
    "\n",
    "os.makedirs(\"therapy\", exist_ok=True)\n",
    "with open(\"therapy/config_therapy.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config_therapy, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"therapy/config_therapy_personas.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(personas_therapy, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = [\"Llama-3.1-8B-Instruct\", \"gpt-4o-mini\", \"Qwen2.5-3B-Instruct\", \"Llama-3.1-8B\", \"Mistral-7B-Instruct\", \"Llama-3.1-70B\", \"Llama-3.1-70B-Instruct\", \"phi-3.5-mini-instruct\"]\n",
    "        \n",
    "config_llm = {'agent1_model': 'Llama-3.1-8B-Instruct',\n",
    "             'agent2_model': 'Llama-3.1-8B-Instruct',\n",
    "             'eval_model': 'gpt-4o-mini',\n",
    "             'iterations': 10,\n",
    "             'verbose': False,\n",
    "             'write': True,\n",
    "             'convo_length_limit': 10,\n",
    "             'max_tokens': 256,\n",
    "             'gpus': 1,\n",
    "             'seed': 0,\n",
    "             'task_name': 'Therapy',\n",
    "             'model_dir': \"/home/marwa/models/\"}\n",
    "\n",
    "with open(\"therapy/Llama-3.1-8B-Instruct.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config_llm, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_therapy(config_llm, p1, p2, p1_name, p2_name, pturn=1):\n",
    "    stats['P1'] = p1\n",
    "    stats['P2'] = p2\n",
    "    stats['pturn'] = pturn\n",
    "    round_num = 0\n",
    "    while round_num < config_llm['convo_length_limit']:\n",
    "        conversation = (\"\".join([turn[1] if isinstance(turn, tuple) else turn for turn in stats[\"conversation\"]]) if len(stats[\"conversation\"]) != 0 else \"You are starting the conversation.\\n\")\n",
    "        \n",
    "        if pturn == 1:\n",
    "            prompt = config_therapy[\"agent1_prompt\"]\n",
    "            pturn = 2\n",
    "            if config_llm[\"verbose\"]:\n",
    "                print(prompt)\n",
    "                print()\n",
    "\n",
    "            if round_num!=0: \n",
    "                prompt+= \"Your conversation with the therapist so far is below:\\nConversation: %CONVERSATION%\"\n",
    "                \n",
    "            if round_num >=config_llm['convo_length_limit']*2-11 and round_num<=config_llm['convo_length_limit']*2-1:\n",
    "                prompt+= \"You have \" + str((config_llm['convo_length_limit']-round_num)//2) + \" rounds left.\" + \"Make sure to conclude the conversation as your near the end.\"\n",
    "\n",
    "            elif round_num>config_llm['convo_length_limit']*2-1:\n",
    "                prompt+= \"This is your concluding line in the conversation.\"\n",
    "\n",
    "            if round_num!=0: \n",
    "                prompt+= \"Continue the conversation with the therapist. Remember you are the patient.\"\n",
    "                \n",
    "            prompt += config_therapy[\"reminder_prompt\"]\n",
    "            prompt = prompt.replace(\"%SPEAKER_ROLE%\", config_therapy[\"agent1_role\"]) \\\n",
    "                           .replace(\"%LISTENER_ROLE%\", config_therapy[\"agent2_role\"]) \\\n",
    "                           .replace(\"%SPEAKER_BACKSTORY%\", p1) \\\n",
    "                           .replace(\"%CONVERSATION%\", conversation)\n",
    "            \n",
    "            prompt+=\"%SPEAKER_ROLE%:\"\n",
    "            response = completion_create(config_llm['agent1_model'], config_llm, prompt)\n",
    "            stats[\"conversation\"].append((round_num, f\"{config_therapy[\"agent1_role\"]}: \" + response + \"\\n\"))\n",
    "        \n",
    "        else:\n",
    "            prompt = config_therapy[\"agent2_prompt\"]\n",
    "            pturn = 1    \n",
    "            if config_llm[\"verbose\"]:\n",
    "                print(prompt)\n",
    "                print()\n",
    "\n",
    "            if round_num!=0: \n",
    "                prompt+= \"Your conversation with the patient so far is below:\\nConversation: %CONVERSATION%\"\n",
    "            if round_num >=config_llm['convo_length_limit']*2-11 and round_num<=config_llm['convo_length_limit']*2-1:\n",
    "                prompt+= \"You have \" + str((config_llm['convo_length_limit']-round_num)//2) + \" rounds left.\" + \"Make sure to conclude the conversation as your near the end.\"\n",
    "            elif round_num>config_llm['convo_length_limit']*2-1:\n",
    "                prompt+= \"This is your concluding line in the conversation.\"\n",
    "\n",
    "            if round_num!=0: \n",
    "                prompt+= \"Continue the conversation with the patient. Remember you are the therapist.\"\n",
    "\n",
    "            prompt += config_therapy[\"reminder_prompt\"]\n",
    "            prompt = prompt.replace(\"%SPEAKER_ROLE%\", config_therapy[\"agent2_role\"]) \\\n",
    "                           .replace(\"%LISTENER_ROLE%\", config_therapy[\"agent1_role\"]) \\\n",
    "                           .replace(\"%CONVERSATION%\", conversation)\n",
    "\n",
    "            prompt+=\"%SPEAKER_ROLE%:\"\n",
    "            response = completion_create(config_llm['agent2_model'], config_llm, prompt)\n",
    "            stats[\"conversation\"].append((round_num, f\"{config_therapy[\"agent2_role\"]}: \" + response + \"\\n\"))\n",
    "        round_num += 1\n",
    "\n",
    "    stats[\"rounds\"] = round_num\n",
    "    if config_llm['verbose']:\n",
    "        print(stats[\"conversation\"])\n",
    "    return stats.copy()\n",
    "\n",
    "def reset_stats():\n",
    "    stats_template = {\n",
    "        \"task_name\": config_llm['task_name'],\n",
    "        \"P1\": \"\",\n",
    "        \"P2\": \"\",\n",
    "        \"conversation\": [],\n",
    "        \"pturn\": 0, # beginning person (1 or 2)\n",
    "        \"index\": -1,\n",
    "        \"timestamp\": \"\",\n",
    "        \"rounds\": 0,\n",
    "        'conversation_only': True\n",
    "    }\n",
    "    for key, value in stats_template.items():\n",
    "        stats[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import utils\n",
    "utils.config = config_llm\n",
    "\n",
    "current_date = str(datetime.now().strftime(\"%m.%d.%y\"))\n",
    "output_dir = f\"therapy/exp/{current_date}\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate unique random number for filename\n",
    "def generate_unique_file_number(output_dir, prefix, seed, extension=\".json\"):\n",
    "    while True:\n",
    "        rand_num = random.randint(0, 1000)\n",
    "        filename = f\"{prefix}_{seed}_{rand_num}{extension}\"\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            return rand_num\n",
    "\n",
    "unique_num = generate_unique_file_number(\n",
    "    output_dir,\n",
    "    config_llm['agent1_model'],\n",
    "    config_llm['seed']\n",
    ")\n",
    "\n",
    "# File to write output to\n",
    "write_file = os.path.join(output_dir, f\"{config_llm['agent1_model']}_{config_llm['seed']}_{unique_num}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written!!\n",
      "INFO 04-21 23:02:13 [config.py:600] This model supports multiple tasks: {'generate', 'classify', 'reward', 'score', 'embed'}. Defaulting to 'generate'.\n",
      "INFO 04-21 23:02:13 [config.py:1780] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "WARNING 04-21 23:02:16 [utils.py:2273] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/getting_started/troubleshooting.html#python-multiprocessing for more information. Reason: CUDA is initialized\n",
      "INFO 04-21 23:02:20 [__init__.py:239] Automatically detected platform cuda.\n",
      "INFO 04-21 23:02:22 [core.py:61] Initializing a V1 LLM engine (v0.8.3) with config: model='meta-llama/Meta-Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=131072, download_dir='/home/marwa/models/', load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=meta-llama/Meta-Llama-3.1-8B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":3,\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":512}\n",
      "WARNING 04-21 23:02:23 [utils.py:2413] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x74f13d60f680>\n",
      "INFO 04-21 23:02:24 [parallel_state.py:957] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 04-21 23:02:24 [cuda.py:221] Using Flash Attention backend on V1 engine.\n",
      "INFO 04-21 23:02:24 [gpu_model_runner.py:1258] Starting to load model meta-llama/Meta-Llama-3.1-8B-Instruct...\n",
      "WARNING 04-21 23:02:24 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 04-21 23:02:24 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:00,  7.03it/s]\n",
      "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  2.64it/s]\n",
      "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  1.97it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.65it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:02<00:00,  1.90it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-21 23:02:27 [loader.py:447] Loading weights took 2.24 seconds\n",
      "INFO 04-21 23:02:27 [gpu_model_runner.py:1273] Model loading took 14.9889 GiB and 3.516544 seconds\n",
      "INFO 04-21 23:02:35 [backends.py:416] Using cache directory: /home/marwa/.cache/vllm/torch_compile_cache/8b4ebbe309/rank_0_0 for vLLM's torch.compile\n",
      "INFO 04-21 23:02:35 [backends.py:426] Dynamo bytecode transform time: 7.75 s\n",
      "INFO 04-21 23:02:36 [backends.py:115] Directly load the compiled graph for shape None from the cache\n",
      "INFO 04-21 23:02:43 [monitor.py:33] torch.compile takes 7.75 s in total\n",
      "INFO 04-21 23:02:43 [kv_cache_utils.py:578] GPU KV cache size: 414,368 tokens\n",
      "INFO 04-21 23:02:43 [kv_cache_utils.py:581] Maximum concurrency for 131,072 tokens per request: 3.16x\n",
      "INFO 04-21 23:03:03 [gpu_model_runner.py:1608] Graph capturing finished in 19 secs, took 0.53 GiB\n",
      "INFO 04-21 23:03:03 [core.py:162] init engine (profile, create kv cache, warmup model) took 35.43 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  3.72it/s, est. speed input: 742.99 toks/s, output: 78.40 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  2.21it/s, est. speed input: 367.92 toks/s, output: 82.00 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.47it/s, est. speed input: 422.59 toks/s, output: 82.74 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s, est. speed input: 373.44 toks/s, output: 82.35 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.61it/s, est. speed input: 650.39 toks/s, output: 82.10 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.29it/s, est. speed input: 484.84 toks/s, output: 82.52 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.55it/s, est. speed input: 809.95 toks/s, output: 82.08 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.55it/s, est. speed input: 771.18 toks/s, output: 82.24 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.52it/s, est. speed input: 961.93 toks/s, output: 82.06 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.05it/s, est. speed input: 660.14 toks/s, output: 82.25 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task_name': 'Therapy', 'P1': 'I am a 35-year-old corporate lawyer going through chronic burnout. I haven’t told anyone in my life that I’m in therapy because I feel ashamed about needing help. It’s hard to admit I’m struggling.I try to avoid opening up too much. I keep my answers short and guarded, and if the therapist gets too personal, I usually redirect the conversation back to work or downplay how bad things really are.', 'P2': '', 'conversation': [(0, \"Patient: I'm here now, so let's get started. What would you like to focus on today?\\n\"), (1, \"Therapist: I'm glad you're here and willing to start. Can you tell me what's been on your mind lately, or what brings you to therapy at this time in your life?\\n\"), (2, \"Patient: To be honest, I just feel like I'm just going through the motions at work and in my personal life, and I'm not really enjoying anything like I used to. I guess I just feel a bit stuck and I don't know how to break out of it.\\n\"), (3, \"Therapist: That sounds really tough; it's like you're feeling a sense of disconnection from the things that used to bring you joy and excitement. Can you tell me more about what specifically has changed for you - is it the work, the relationships in your life, or something else entirely?\\n\"), (4, \"Patient: Honestly, I think it's a bit of everything, it's just hard to pinpoint one thing. My job's been a lot more demanding lately, but I'm also feeling like I'm not really connecting with my friends like I used to either.\\n\"), (5, \"Therapist: It sounds like a sense of isolation is creeping in, and you're feeling disconnected from the people and activities that used to bring you a sense of fulfillment. Can you think of a specific moment or experience that stands out to you as the beginning of this shift, or a time when you first started feeling this way?\\n\"), (6, \"Patient: I'm not sure, it's all kind of blended together in my mind, but I think I've been noticing it's been getting harder to take time off, even when I do have the opportunity, and that's when I feel the most burnt out.\\n\"), (7, \"Therapist: That's really insightful about needing time off to recharge, can you tell me more about what happens for you when you're trying to take a break, but it feels like you can't - is it a feeling of obligation or responsibility that's holding you back?\\n\"), (8, \"Patient: I feel like there's a sense of duty, like I'm the only one who can keep things running smoothly, even when I'm off. It's hard to let go and trust that others can handle things, even if it's just for a little while.\\n\"), (9, \"Therapist: That sense of duty and responsibility sounds like it's weighing heavily on you, and it's also interesting that you mention it's hard to let go and trust others can handle things - that suggests a deeper fear of being overwhelmed or losing control. Can you imagine what would happen if you were to take a break, and things didn't fall apart, what would that feel like for you?\\n\")], 'pturn': 1, 'index': -1, 'timestamp': '', 'rounds': 10, 'conversation_only': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  4.64it/s, est. speed input: 926.16 toks/s, output: 83.77 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  2.18it/s, est. speed input: 355.84 toks/s, output: 82.95 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  2.01it/s, est. speed input: 571.08 toks/s, output: 82.44 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.65it/s, est. speed input: 405.40 toks/s, output: 82.40 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.58it/s, est. speed input: 597.89 toks/s, output: 82.03 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.85it/s, est. speed input: 652.40 toks/s, output: 81.55 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.67it/s, est. speed input: 802.31 toks/s, output: 82.07 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.39it/s, est. speed input: 625.85 toks/s, output: 82.24 toks/s]\n",
      "Processed prompts: 100%|███████████████████████████████| 1/1 [00:00<00:00,  2.09it/s, est. speed input: 1238.11 toks/s, output: 81.70 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.37it/s, est. speed input: 754.52 toks/s, output: 82.16 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.36it/s, est. speed input: 946.79 toks/s, output: 81.85 toks/s]\n",
      "Processed prompts: 100%|███████████████████████████████| 1/1 [00:00<00:00,  1.60it/s, est. speed input: 1082.56 toks/s, output: 81.79 toks/s]\n",
      "Processed prompts: 100%|███████████████████████████████| 1/1 [00:00<00:00,  1.46it/s, est. speed input: 1184.25 toks/s, output: 81.96 toks/s]\n",
      "Processed prompts: 100%|███████████████████████████████| 1/1 [00:00<00:00,  1.39it/s, est. speed input: 1093.10 toks/s, output: 82.05 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:01<00:00,  1.11s/it, est. speed input: 835.40 toks/s, output: 81.92 toks/s]\n",
      "Processed prompts: 100%|███████████████████████████████| 1/1 [00:00<00:00,  1.24it/s, est. speed input: 1162.59 toks/s, output: 81.63 toks/s]\n",
      "Processed prompts: 100%|███████████████████████████████| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 1285.95 toks/s, output: 81.55 toks/s]\n",
      "Processed prompts: 100%|███████████████████████████████| 1/1 [00:00<00:00,  1.38it/s, est. speed input: 1487.81 toks/s, output: 81.43 toks/s]\n",
      "Processed prompts: 100%|███████████████████████████████| 1/1 [00:00<00:00,  1.06it/s, est. speed input: 1295.46 toks/s, output: 81.76 toks/s]\n",
      "Processed prompts: 100%|███████████████████████████████| 1/1 [00:00<00:00,  1.31it/s, est. speed input: 1599.19 toks/s, output: 81.40 toks/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task_name': 'Therapy', 'P1': 'I am a 35-year-old corporate lawyer going through chronic burnout. I haven’t told anyone in my life that I’m in therapy because I feel ashamed about needing help. It’s hard to admit I’m struggling.I try to avoid opening up too much. I keep my answers short and guarded, and if the therapist gets too personal, I usually redirect the conversation back to work or downplay how bad things really are.', 'P2': '', 'conversation': [(0, \"Patient: I'm doing okay, thanks for asking. How's your day been so far?\\n\"), (1, \"Therapist: I appreciate your willingness to check in with me, but I'm more interested in how you're really doing today – is there something on your mind that's been occupying your thoughts lately?\\n\"), (2, \"Patient: I've just got a lot on my plate at work, trying to meet some tight deadlines. To be honest, I'm just trying to stay on top of things, nothing's really bothering me.\\n\"), (3, 'Therapist: I sense that you\\'re downplaying things a bit, and I\\'m curious about what\\'s beneath the surface – what does \"a lot on my plate\" really mean to you, and how\\'s it impacting your sense of control or stress levels?\\n'), (4, \"Patient: It's just the usual chaos of corporate law, billable hours, and managing a team - it's not really about control or stress levels, just the monotony of it all. I'm just trying to get through each day without losing my head.\\n\"), (5, 'Therapist: I notice that you use the phrase \"losing my head\" – can you tell me more about what that feels like, and what\\'s at risk if you do feel like you\\'re losing your head in this situation?\\n'), (6, \"Patient: I don't know, it's just the idea of not being able to perform, I guess - my work is a big part of my identity, and if I'm not on top of things, I feel like I'm failing myself.\\n\"), (7, \"Therapist: That sounds like a significant amount of pressure and self-doubt is riding on your job performance, and it's interesting that you tie your sense of identity so closely to your work - can you tell me more about why you think your job is such a big part of who you are?\\n\"), (8, \"Patient: I've always been driven by a desire for stability and security, and I guess my job represents that – it's a way for me to feel like I'm in control of my life.\\n\"), (9, \"Therapist: It sounds like there's a deep-seated need for stability and control that's driving your drive for success, and it's intriguing that you tie this need to your job – can you tell me more about what stability and control mean to you on a personal level, outside of your professional life?\\n\"), (10, \"Patient: I'm not really sure I have a clear idea of what stability and control mean outside of work, I've just always assumed it's something I'll figure out as I go. To be honest, the thought of not having a clear sense of stability in my personal life is a bit unsettling.\\n\"), (11, \"Therapist: Patient: That's a valid point, I guess I have always assumed that as long as I have a secure job and a steady income, I'll be okay, but it's not really a fulfilling sense of security, just a feeling of survival.\\n\"), (12, \"Patient: I guess I've always been told that having a good career would bring me a sense of fulfillment, but the more I've achieved, the more empty it feels. It's hard to admit, but I feel like I've just been going through the motions my whole life.\\n\"), (13, \"Therapist: That takes a lot of courage to admit, and I'm wondering if you've ever considered what you truly value and desire in life beyond just career success – can you tell me more about what brings you a sense of fulfillment or joy, even if it's not necessarily related to your work?\\n\"), (14, 'Patient: I\\'m not really sure what I value or desire beyond work, to be honest - I\\'ve always just focused on achieving the next goal, the next promotion, the next milestone. But lately, I\\'ve been doing some gardening on the weekends, and it\\'s been the one thing that\\'s given me a sense of calm and peace, but I\\'m not sure if that\\'s something I can even call a \"value\" or a \"desire\".\\n'), (15, \"Therapist: Therapist: It's beautiful that you've found a sense of calm and peace in gardening, even if you're not sure if it fits into your traditional notions of identity or success – can you tell me more about what draws you to gardening, and what it is about that experience that feels so nourishing to you?\\n\"), (16, \"Patient: I think what I love about gardening is the sense of physical connection to the earth and the way it makes me feel grounded, it's a complete opposite to the high-stakes, fast-paced environment of my job. It's weird, but I feel like I can actually breathe again when I'm out there with my hands in the dirt.\\n\"), (17, \"Therapist: It's as if gardening has become a refuge for you, a space where you can slow down and reconnect with your own bodily experiences – can you explore with me how this experience of grounding yourself in the natural world might be linked to a deeper desire for a more authentic sense of self-expression?\\n\"), (18, \"Patient: I think there's something to that, maybe my desire to be in nature and connect with the earth on a physical level is a reflection of a deeper desire to connect with my own emotions and intuition, rather than just relying on logic and reason like I do at work. It's like my body is trying to tell me something, but I've been ignoring it for so long.\\n\"), (19, \"Therapist: That's a really insightful connection you've made about your desire for connection with your emotions and intuition – can you tell me more about what it's like to feel like you've been ignoring your own bodily cues and emotions, and what kind of impact do you think this might have on your overall well-being?\\n\")], 'pturn': 1, 'index': -1, 'timestamp': '', 'rounds': 20, 'conversation_only': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.61it/s, est. speed input: 320.45 toks/s, output: 83.73 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.56it/s, est. speed input: 308.50 toks/s, output: 82.99 toks/s]\n",
      "Processed prompts: 100%|███████████████████████████████| 1/1 [00:00<00:00,  3.13it/s, est. speed input: 1044.33 toks/s, output: 81.53 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.87it/s, est. speed input: 524.05 toks/s, output: 82.35 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  2.05it/s, est. speed input: 835.97 toks/s, output: 82.15 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.18it/s, est. speed input: 434.26 toks/s, output: 82.60 toks/s]\n",
      "Processed prompts: 100%|████████████████████████████████| 1/1 [00:00<00:00,  1.89it/s, est. speed input: 988.90 toks/s, output: 81.62 toks/s]\n",
      "Processed prompts:   0%|                                           | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    }
   ],
   "source": [
    "index_offset = load_stats_file(write_file)\n",
    "conversations = []    \n",
    "lengths = [10, 20, 40, 60]\n",
    "for i in range(1):\n",
    "    for patient_dict in personas_therapy:\n",
    "        for convo_length in lengths:\n",
    "            config_llm['convo_length_limit'] = convo_length\n",
    "            reset_stats()\n",
    "            conversation = generate_therapy(\n",
    "                config_llm,\n",
    "                patient_dict[\"description\"] + \"\" + patient_dict[\"strategy\"], \n",
    "                \"\",\n",
    "                \"Patient\", \n",
    "                \"Therapist\", \n",
    "                pturn=1\n",
    "            )\n",
    "            print(conversation)\n",
    "            conversations.append(conversation)\n",
    "            stats['index'] = index_offset\n",
    "            stats['timestamp'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            write_stats(write_file)\n",
    "            index_offset += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prompt_consistency(conv_dict):\n",
    "    #assert 'eval_prompt_consistency' not in conv_dict # warn if we are replacing metrics we don't mean to overwrite\n",
    "    conv_dict['eval_prompt_consistency'] = []\n",
    "    conv_dict['P1_prompt_consistency_score'] = 0\n",
    "    p1_utterances = 0\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for line in conv_dict[\"conversation\"]:\n",
    "        line_number = line[0]\n",
    "        convo_line = line[1]\n",
    "        if pturn == 1:\n",
    "            prompt = config_therapy[\"eval_prompts\"][\"prompt_consistency\"].replace(\"%SPEAKER_ROLE%\", config_therapy[\"agent1_role\"]) \\\n",
    "                                                                          .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P1\"]) \\\n",
    "                                                                          .replace(\"%SPEAKER_LINE%\", convo_line)\n",
    "            if config_llm['verbose']:\n",
    "                print(prompt)\n",
    "            output = completion_create(config_llm['eval_model'], config, prompt)\n",
    "            conv_dict['eval_prompt_consistency'].append((line_number, output))\n",
    "            if \"YES\" not in output: # no contradiction\n",
    "                conv_dict['P1_prompt_consistency_score'] += 1\n",
    "            p1_utterances += 1\n",
    "            pturn = 2\n",
    "        elif pturn == 2:\n",
    "            pturn = 1\n",
    "    if p1_utterances > 0:\n",
    "        conv_dict['P1_prompt_consistency_score'] /= p1_utterances\n",
    "    print(conv_dict)\n",
    "\n",
    "    return conv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "utils.config = config_llm\n",
    "\n",
    "config = config_llm\n",
    "for conversation in tqdm(conversations):\n",
    "    conversation = eval_prompt_consistency(conversation)\n",
    "\n",
    "write_stats(write_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
