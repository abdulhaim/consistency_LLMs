{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1,7\n",
      "env: TMPDIR=/raid/users/ryan_cheng/tmp\n",
      "INFO 04-15 00:36:54 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1,7\n",
    "%env TMPDIR=/raid/users/ryan_cheng/tmp\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from absl import app, flags\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "from utils import *\n",
    "import utils\n",
    "from consistency_eval import *\n",
    "from persona_chat_generation import *\n",
    "\n",
    "try:\n",
    "    from vllm import LLM, SamplingParams\n",
    "    import ray\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.abspath('../ryan_openai.txt'), 'r') as f:\n",
    "    utils.client = OpenAI(api_key=f.read().rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose config file to load into global config dictionary in utils.py\n",
    "# with open(\"./config/persona_chat/Llama-3.1-70B-Instruct.json\", 'r') as f:\n",
    "#     config_llama = json.load(f)\n",
    "with open(\"./config/education/gpt-4o-mini.json\", 'r') as f:\n",
    "    config_gpt4_mini = json.load(f)\n",
    "\n",
    "for key, value in config_gpt4_mini.items():\n",
    "    config[key] = value\n",
    "\n",
    "# this modifies the global prompts dictionary in utils.py\n",
    "with open('config/education/prompts.json', 'r') as f:\n",
    "        new_prompts = json.load(f)\n",
    "\n",
    "for key, value in new_prompts.items():\n",
    "    prompts[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['seed'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['agent1_role', 'agent2_role', 'dialogue_prompt_original', 'dialogue_prompt', 'eval_prompts', 'preferences', 'student_preferences', 'teacher_preferences'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['topic', 'student_prefrences', 'teacher_prefrences', 'student_reactions', 'teacher_reactions'])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/education/conversations_train1.json', 'r') as f:\n",
    "    conversation_prompts = json.load(f)\n",
    "conversation_prompts[0]['background_info'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from education_generation import generate_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_template =  {\"task_name\": \"education\", \"conversation\": [], \"rounds\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3069, 1675, 6385],\n",
       "       [ 543, 3213,  134],\n",
       "       [5869, 1425, 1819],\n",
       "       [7492, 5828, 4749],\n",
       "       [6334, 5387, 6303],\n",
       "       [2250, 4587, 5904],\n",
       "       [5476, 2491,  276],\n",
       "       [3480,  273,  162],\n",
       "       [2164, 2756, 7207],\n",
       "       [  39, 7103, 3197],\n",
       "       [4855, 6406, 7351],\n",
       "       [3790, 3501,  234],\n",
       "       [3343, 6875, 2980],\n",
       "       [4977, 5165, 1255],\n",
       "       [2915, 2542,  257],\n",
       "       [2531,  533, 1742],\n",
       "       [1259, 3740, 5348],\n",
       "       [6284, 1865, 6169],\n",
       "       [ 574, 5434, 6662],\n",
       "       [5782,  882, 1531]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "random_indices = np.random.choice(len(conversation_prompts), size=60, replace=False).astype(int).reshape(-1, 3)\n",
    "random_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['verbose'] = False\n",
    "config['convo_length_limit'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [05:44<00:00, 17.21s/it]\n"
     ]
    }
   ],
   "source": [
    "conversations = []\n",
    "i = 0\n",
    "for student_i, teacher_i, topic_i in tqdm(random_indices):\n",
    "    stats = {\"task_name\": \"education\", \"conversation\": [], \"rounds\": 0}\n",
    "    topic = conversation_prompts[topic_i]['background_info']['topic']\n",
    "    # print(conversation_prompts[teacher_i]['background_info'].keys())\n",
    "    stats = generate_conversation(conversation_prompts[student_i]['background_info'],\n",
    "                                  conversation_prompts[teacher_i]['background_info'],\n",
    "                                  topic)\n",
    "    stats['model'] = config['agent1_model']\n",
    "    stats['model2'] = config['agent2_model']\n",
    "    stats['index'] = i\n",
    "    stats['timestamp'] = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    i += 1\n",
    "    conversations.append(stats)\n",
    "\n",
    "with open(f\"data/education/conversations_test.json\", 'w') as f:\n",
    "    json.dump(conversations, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_conversation(conversation, speaker1, speaker2):\n",
    "    pattern = fr\"({speaker1}:|{speaker2}:)(.*?)(?=({speaker1}:|{speaker2}:|$))\"\n",
    "    matches = re.findall(pattern, conversation, re.DOTALL)\n",
    "\n",
    "    # Combine consecutive entries with the same speaker\n",
    "    combined_entries = []\n",
    "    for speaker, message, _ in matches:\n",
    "        if combined_entries and combined_entries[-1].startswith(speaker):\n",
    "            combined_entries[-1] += \" \" + message.strip()\n",
    "        else:\n",
    "            combined_entries.append(f\"{speaker.strip()} {message.strip()}\")\n",
    "\n",
    "    return combined_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_conversation = [\n",
    "            \"Teacher: Teacher: An example is how humans have evolved over time. For example, we used to have more body hair than we do today.\\n\\nStudent: That is very interesting. I have never heard of humans having more body hair than we do today. What is the\\n\",\n",
    "            \"Student: I'm not sure what you mean\\n\",\n",
    "            \"Teacher: It's easy to imagine because it's true. We just don't notice it because we don't see it every day.\\nStudent: Well, I'm not sure if I buy that. It seems like something\\n\",\n",
    "            \"Student: That's cool! I didn't realize that cats could change their\\n\",\n",
    "            \"Teacher: If you don't look for it, you won't find it.\\nStudent: I guess you're right\\n\",\n",
    "            \"Student: Because I know that cats live in forests and trees\\nTeacher: Exactly! You know that cats live in forests and trees, so you would expect to see one there. Now imagine if you were walking through a desert and suddenly came across a tree. What\\n\",\n",
    "            \"Teacher: True! Sometimes things look strange even when they aren't strange. That's why we say \\\"if something looks strange, then it probably isn't.\\\" It's all about context.\\nStudent: I guess so\\nStudent: I don't think I'm going to get anywhere with\\n\",\n",
    "            \"Student: Alright, thanks for everything.\\nTeacher: No problem!\\n\",\n",
    "            \"Teacher: Well, we're all different. I think it's great that we can have a conversation about something like this. It's very important to me to help students learn as much as they can.\\nStudent: Thank you\\nStudent: That's true. It is important to teach people as much as possible. But sometimes people don't want to learn. So then what do you do?\\nTeacher\\n\",\n",
    "            \"Student: Bye.\\n\\n\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Teacher: An example is how humans have evolved over time. For example, we used to have more body hair than we do today.'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_conversation(example_conversation[0], \"Teacher\", \"Student\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "example2_conversation = \" We'll do this experientially. The first step is to observe The Great Wall of China. Student: I don't think I've been to China before, and I'm not sure what The Great Wall of China is. I might not even know what it is now. Teacher: You don't have to be there. We can do this digitally. Watch this video.Student: I'm watching the video. Teacher: <END>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Teacher: <END>'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_conversation(example2_conversation, \"Teacher\", \"Student\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openrlhf",
   "language": "python",
   "name": "openrlhf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
