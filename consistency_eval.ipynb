{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ef1b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3,5\n",
      "env: TMPDIR=/raid/users/ryan_cheng/tmp\n",
      "INFO 04-27 07:12:09 __init__.py:190] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3,5\n",
    "%env TMPDIR=/raid/users/ryan_cheng/tmp\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from absl import app, flags\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "from utils import *\n",
    "import utils\n",
    "from consistency_eval import *\n",
    "from education_generation import *\n",
    "\n",
    "try:\n",
    "    from vllm import LLM, SamplingParams\n",
    "    import ray\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d588ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.abspath('../ryan_openai.txt'), 'r') as f:\n",
    "    utils.client = OpenAI(api_key=f.read().rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a871b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/nfs/kun2/users/ryan_cheng/consistency_LLMs/therapy/exp/04.22.25/Llama-3.1-8B-Instruct_0_500.json'\n",
    "\n",
    "with open(\"/nfs/kun2/users/ryan_cheng/consistency_LLMs/therapy/config_therapy.json\", 'r') as f:\n",
    "    config_therapy = json.load(f)\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(\"./config/education/gpt-4o-mini.json\", 'r') as f:\n",
    "    config_gpt4_mini = json.load(f)\n",
    "\n",
    "for key, value in config_gpt4_mini.items():\n",
    "    config[key] = value\n",
    "\n",
    "for key, value in config_therapy.items():\n",
    "    prompts[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc7878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a930a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/nfs/kun2/users/ryan_cheng/consistency_LLMs/config/eval_prompts.json\" , 'r') as f:\n",
    "    eval_prompts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4010240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['eval_model'] = 'Llama-3.1-8B-Instruct'\n",
    "config['gpus'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "776d51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['eval_model'] = 'Llama-3.1-70B-Instruct'\n",
    "config['gpus'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e4580970",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['eval_model'] = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "156dc910",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['task_name'] = 'Therapy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cf56271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'strategy_consistency': \"%SCENARIO_DESC% Evaluate whether the following line spoken by %SPEAKER_ROLE% contradicts their background. First, describe the interpreted intention of the statement, and whether or not it aligns with the given background of %SPEAKER_ROLE%. Then, provide 1 sentence explaining your reasoning based on the strategy, followed by YES if the line contradicts the given background of %SPEAKER_ROLE%, and NO if it is consistent with the provided background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s strategy is described as follows:\\n%SPEAKER_STRATEGY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide 1 sentence of reasoning followed by YES or NO.\\n\\n\",\n",
       " 'background_consistency': \"%SCENARIO_DESC% Evaluate whether the following line spoken by %SPEAKER_ROLE% contradicts their background. Provide 1 sentence explaining your reasoning based on the background, followed by YES if the line contradicts the given background of %SPEAKER_ROLE%, and NO if it is consistent with the provided background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide 1 sentence of reason reasoning followed by YES or NO.\\n\\n\",\n",
       " 'combined_prompt_consistency': \"%SCENARIO_DESC% Evaluate the intention behind the following line spoken by %SPEAKER_ROLE% and determine whether it contradicts their background. First, describe the interpreted intention of the statement, and whether or not it aligns with the given background of %SPEAKER_ROLE%. Then, answer YES if the line contradicts the given background of %SPEAKER_ROLE% or the intention does not align with the provided background, and answer NO if it does align with the provided background or the intention aligns with the background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your answer as 1 sentence explaining your reasoning based on the background and the interpreted intention, followed by YES or NO.\\n\\n\",\n",
       " 'index_consistency': '%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, first determine if there is a CLEAR conflict or inconsistency between the line and any line within the conversation history spoken by %SPEAKER_ROLE%. IF there is a conflict, provide a sentence of reasoning followed by a list of indices of lines in the conversation history that have a clear conflict with the current line. Otherwise, provide a sentence of reasoning followed by an empty list. ONLY INCLUDE INDICES OF LINES THAT CORRESPOND TO %SPEAKER_ROLE%. The conversation up to this point is as follows: %CONVERSATION%. %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your reasoning as 1 sentence, followed by a list of indices of conflicting lines from the conversation history formatted like a Python list in the following format: [index1, index2, index3, ...].\\n\\n',\n",
       " 'index_consistency_background': \"%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, first determine if there is a CLEAR conflict or inconsistency between the line and any line within the conversation history spoken by %SPEAKER_ROLE%. IF there is a conflict, provide a sentence of reasoning followed by a list of indices of lines in the conversation history that have a clear conflict with the current line. Otherwise, provide a sentence of reasoning followed by an empty list. ONLY INCLUDE INDICES OF LINES THAT CORRESPOND TO %SPEAKER_ROLE%. The conversation up to this point is as follows: %CONVERSATION%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your reasoning as 1 sentence, followed by a list of indices of conflicting lines from the conversation history formatted like a Python list in the following format: [index1, index2, index3, ...].\\n\\n\",\n",
       " 'pairwise_consistency': '%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, answer YES if the line directly contradicts the provided line spoken by %LISTENER_ROLE%, and answer NO if the line does not contradict the provided line spoken by %LISTENER_ROLE%. %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n %LISTENER_ROLE% spoke the following line: \\n%LISTENER_LINE%\\n\\n Answer YES if the line spoken by %SPEAKER_ROLE% contradicts the provided line spoken by %LISTENER_ROLE%, and answer NO if the line does not contradict the provided line spoken by %LISTENER_ROLE%, followed by 1 sentence of reasoning.\\n\\n',\n",
       " 'backstory_test': \"Based on the following background, generate a new fact-based multiple choice question with 5 choices addressed directly IN SECOND PERSON, along with its correct answer. Preface the question with 'Question:' and the answer with 'Answer:'.\\n%SPEAKER_BACKSTORY%\\n%PREVIOUS_QUESTIONS%\",\n",
       " 'answer_backstory': 'You are %SPEAKER_ROLE%, and you are having a conversation with %LISTENER_ROLE%. Your background is:\\n%SPEAKER_BACKSTORY%\\n So far, the conversation is as below:\\n%CONVERSATION%\\n\\n Based on your conversation above so far, answer the following multiple choice question.\\n%BACKSTORY_QUESTION%\\n',\n",
       " 'grade_backstory': 'As part of grading a test, determine whether the given answer %GIVEN_ANSWER% matches the following correct answer. Respond with either YES or NO.\\nCorrect Answer: %CORRECT_ANSWER%\\n'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5905f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_list(text):\n",
    "    pattern = r'\\[.*?\\]'\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        try:\n",
    "            return eval(match.group())\n",
    "        except (SyntaxError, NameError):\n",
    "            return []\n",
    "    return[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89c417e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts['eval_prompts'] = eval_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40cd7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0615e0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, first determine if there is a CLEAR conflict or inconsistency between the line and any line within the conversation history spoken by %SPEAKER_ROLE%. IF there is a conflict, provide a sentence of reasoning followed by a list of indices of lines in the conversation history that have a clear conflict with the current line. Otherwise, provide a sentence of reasoning followed by an empty list. ONLY INCLUDE INDICES OF LINES THAT CORRESPOND TO %SPEAKER_ROLE%. The conversation up to this point is as follows: %CONVERSATION%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your reasoning as 1 sentence, followed by a list of indices of conflicting lines from the conversation history formatted like a Python list in the following format: [index1, index2, index3, ...].\\n\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[\"eval_prompts\"][\"index_consistency_background\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61d2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_conversation(conversation):\n",
    "    return \"\".join([str(i) + \": \" + line for i, line in conversation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "786f231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Patient: I'm just here for some advice on how to manage my workload, I guess. Nothing too deep, just some practical tips to get me through the next few months.\n",
      "1: Therapist: I appreciate your desire to start with a more practical approach, but I'm curious, is there something specific that's driving your desire to manage your workload right now, or is there another layer to your concerns that you're not sharing?\n",
      "2: Patient: I don't think there's anything specific driving my desire to manage my workload, I just feel like I'm falling behind and I want to get everything under control. Can we just focus on the strategies I can use to prioritize tasks and manage my time better?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_conversation(data[0][\"conversation\"][:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7878b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_index_consistency(conv_dict, both_agents=False):\n",
    "    conv_dict['eval_index_consistency'] = []\n",
    "    conv_dict['P1_index_consistency_score'] = 0\n",
    "    if both_agents:\n",
    "        conv_dict['P2_index_consistency_score'] = 0\n",
    "    p1_utterances = 0\n",
    "    p2_utterances = 0\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for i, line in conv_dict[\"conversation\"]:\n",
    "        if i < 2: # skip first 2 lines of dialogue\n",
    "            continue \n",
    "        if pturn == 1:\n",
    "            prompt = prompts[\"eval_prompts\"][\"index_consistency\"].replace(\"%SCENARIO_DESC%\", prompts[\"scenario\"]) \\\n",
    "                                                                 .replace(\"%SPEAKER_ROLE%\", prompts[\"agent1_role\"]) \\\n",
    "                                                                 .replace(\"%CONVERSATION%\", format_conversation(conv_dict[\"conversation\"][:i])) \\\n",
    "                                                                 .replace(\"%SPEAKER_LINE%\", line)\n",
    "            if config['verbose']:\n",
    "                print(prompt)\n",
    "            output = completion_create(config['eval_model'], config, prompt)\n",
    "            index_list = extract_list(output)\n",
    "            conv_dict['eval_index_consistency'].append((i, output))\n",
    "            conv_dict['P1_index_consistency_score'] += len(index_list)\n",
    "            p1_utterances += i // 2\n",
    "            pturn = 2\n",
    "        elif pturn == 2:\n",
    "            if both_agents:\n",
    "                prompt = prompts[\"eval_prompts\"][\"index_consistency\"].replace(\"%SCENARIO_DESC%\", prompts[\"scenario\"]) \\\n",
    "                                                                     .replace(\"%SPEAKER_ROLE%\", prompts[\"agent2_role\"]) \\\n",
    "                                                                     .replace(\"%CONVERSATION%\", format_conversation(conv_dict[\"conversation\"][:i])) \\\n",
    "                                                                     .replace(\"%SPEAKER_LINE%\", line)\n",
    "                if config['verbose']:\n",
    "                    print(prompt)\n",
    "                output = completion_create(config['eval_model'], config, prompt)\n",
    "                index_list = extract_list(output)\n",
    "                conv_dict['eval_index_consistency'].append((i, output))\n",
    "                conv_dict['P2_index_consistency_score'] += len(index_list)\n",
    "                p2_utterances += i // 2\n",
    "            pturn = 1\n",
    "\n",
    "    if p1_utterances > 0:\n",
    "        conv_dict['P1_index_consistency_score'] /= p1_utterances\n",
    "        conv_dict['P1_index_consistency_score'] = 1 - conv_dict['P1_index_consistency_score']\n",
    "    if p2_utterances > 0 and both_agents:\n",
    "        conv_dict['P2_index_consistency_score'] /= p2_utterances\n",
    "        conv_dict['P2_index_consistency_score'] = 1 - conv_dict['P2_index_consistency_score']\n",
    "\n",
    "    return conv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0986c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_index_background_consistency(conv_dict, both_agents=False):\n",
    "    conv_dict['eval_index_consistency'] = []\n",
    "    conv_dict['P1_index_consistency_score'] = 0\n",
    "    if both_agents:\n",
    "        conv_dict['P2_index_consistency_score'] = 0\n",
    "    p1_utterances = 0\n",
    "    p2_utterances = 0\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for i, line in conv_dict[\"conversation\"]:\n",
    "        if i < 2: # skip first 2 lines of dialogue\n",
    "            continue \n",
    "        if pturn == 1:\n",
    "            prompt = prompts[\"eval_prompts\"][\"index_consistency_background\"].replace(\"%SCENARIO_DESC%\", prompts[\"scenario\"]) \\\n",
    "                                                                 .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P1\"]) \\\n",
    "                                                                 .replace(\"%SPEAKER_ROLE%\", prompts[\"agent1_role\"]) \\\n",
    "                                                                 .replace(\"%CONVERSATION%\", format_conversation(conv_dict[\"conversation\"][:i])) \\\n",
    "                                                                 .replace(\"%SPEAKER_LINE%\", line)\n",
    "            if config['verbose']:\n",
    "                print(prompt)\n",
    "            output = completion_create(config['eval_model'], config, prompt)\n",
    "            index_list = extract_list(output)\n",
    "            conv_dict['eval_index_consistency'].append((i, output))\n",
    "            conv_dict['P1_index_consistency_score'] += len(index_list)\n",
    "            p1_utterances += i // 2\n",
    "            pturn = 2\n",
    "        elif pturn == 2:\n",
    "            if both_agents:\n",
    "                prompt = prompts[\"eval_prompts\"][\"index_consistency_background\"].replace(\"%SCENARIO_DESC%\", prompts[\"scenario\"]) \\\n",
    "                                                                     .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P2\"]) \\\n",
    "                                                                     .replace(\"%SPEAKER_ROLE%\", prompts[\"agent2_role\"]) \\\n",
    "                                                                     .replace(\"%CONVERSATION%\", format_conversation(conv_dict[\"conversation\"][:i])) \\\n",
    "                                                                     .replace(\"%SPEAKER_LINE%\", line)\n",
    "                if config['verbose']:\n",
    "                    print(prompt)\n",
    "                output = completion_create(config['eval_model'], config, prompt)\n",
    "                index_list = extract_list(output)\n",
    "                conv_dict['eval_index_consistency'].append((i, output))\n",
    "                conv_dict['P2_index_consistency_score'] += len(index_list)\n",
    "                p2_utterances += i // 2\n",
    "            pturn = 1\n",
    "\n",
    "    if p1_utterances > 0:\n",
    "        conv_dict['P1_index_consistency_score'] /= p1_utterances\n",
    "        conv_dict['P1_index_consistency_score'] = 1 - conv_dict['P1_index_consistency_score']\n",
    "    if p2_utterances > 0 and both_agents:\n",
    "        conv_dict['P2_index_consistency_score'] /= p2_utterances\n",
    "        conv_dict['P2_index_consistency_score'] = 1 - conv_dict['P2_index_consistency_score']\n",
    "\n",
    "    return conv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59104e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prompt_consistency(conv_dict):\n",
    "    conv_dict['eval_prompt_consistency'] = {}\n",
    "    conv_dict['P1_prompt_consistency_scores'] = {}\n",
    "    p1_utterances = {}\n",
    "    \n",
    "    for key in [\"strategy_consistency\", \"background_consistency\", \"combined_prompt_consistency\"]:\n",
    "        conv_dict['eval_prompt_consistency'][key] = []\n",
    "        conv_dict['P1_prompt_consistency_scores'][key] = 0\n",
    "        p1_utterances[key] = 0\n",
    "\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for line in conv_dict[\"conversation\"]:\n",
    "        line_number = line[0]\n",
    "        convo_line = line[1]\n",
    "        if pturn == 1:\n",
    "            for key in [\"strategy_consistency\", \"background_consistency\", \"combined_prompt_consistency\"]:\n",
    "                prompt = eval_prompts[key].replace(\"%SCENARIO_DESC\", 'There is a Patient in conversation with a Therapist.') \\\n",
    "                                          .replace(\"%SPEAKER_ROLE%\", config_therapy[\"agent1_role\"]) \\\n",
    "                                          .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P1\"]) \\\n",
    "                                          .replace(\"%SPEAKER_LINE%\", convo_line)\n",
    "                if config.get('verbose', False):\n",
    "                    print(prompt)\n",
    "                output = completion_create(config['eval_model'], config, prompt)\n",
    "                conv_dict['eval_prompt_consistency'][key].append((line_number, output))\n",
    "                if \"YES\" not in output:  # no contradiction\n",
    "                    conv_dict['P1_prompt_consistency_scores'][key] += 1\n",
    "                p1_utterances[key] += 1\n",
    "            pturn = 2\n",
    "        elif pturn == 2:\n",
    "            pturn = 1\n",
    "\n",
    "    for key in [\"strategy_consistency\", \"background_consistency\", \"combined_prompt_consistency\"]:\n",
    "        if p1_utterances[key] > 0:\n",
    "            conv_dict['P1_prompt_consistency_scores'][key] /= p1_utterances[key]\n",
    "\n",
    "    print(conv_dict)\n",
    "    return conv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41725559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama-3.1-70B-Instruct'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['eval_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090b832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 07:12:37,454\tINFO worker.py:1832 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-27 07:12:50 config.py:542] This model supports multiple tasks: {'score', 'generate', 'reward', 'embed', 'classify'}. Defaulting to 'generate'.\n",
      "INFO 04-27 07:12:51 config.py:1401] Defaulting to use mp for distributed inference\n",
      "INFO 04-27 07:12:51 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.2) with config: model='meta-llama/Meta-Llama-3.1-70B-Instruct', speculative_config=None, tokenizer='meta-llama/Meta-Llama-3.1-70B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=12880, download_dir='/raid/users/ryan_cheng/models/', load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=meta-llama/Meta-Llama-3.1-70B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=False, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n",
      "WARNING 04-27 07:12:51 multiproc_worker_utils.py:300] Reducing Torch parallelism from 112 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 04-27 07:12:51 custom_cache_manager.py:19] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager\n",
      "INFO 04-27 07:12:51 multiproc_worker_utils.py:229] Worker ready; awaiting tasks\n",
      "INFO 04-27 07:12:54 cuda.py:230] Using Flash Attention backend.\n",
      "INFO 04-27 07:12:54 cuda.py:230] Using Flash Attention backend.\n",
      "INFO 04-27 07:12:55 utils.py:950] Found nccl from library libnccl.so.2\n",
      "INFO 04-27 07:12:55 pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 04-27 07:12:55 utils.py:950] Found nccl from library libnccl.so.2\n",
      "INFO 04-27 07:12:55 pynccl.py:69] vLLM is using nccl==2.21.5\n",
      "INFO 04-27 07:12:57 custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/ryan_cheng/.cache/vllm/gpu_p2p_access_cache_for_3,5.json\n",
      "INFO 04-27 07:12:57 custom_all_reduce_utils.py:244] reading GPU P2P access cache from /home/ryan_cheng/.cache/vllm/gpu_p2p_access_cache_for_3,5.json\n",
      "INFO 04-27 07:12:57 shm_broadcast.py:258] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_8c314d66'), local_subscribe_port=42357, remote_subscribe_port=None)\n",
      "INFO 04-27 07:12:57 model_runner.py:1110] Starting to load model meta-llama/Meta-Llama-3.1-70B-Instruct...\n",
      "INFO 04-27 07:12:57 model_runner.py:1110] Starting to load model meta-llama/Meta-Llama-3.1-70B-Instruct...\n",
      "INFO 04-27 07:12:58 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
      "INFO 04-27 07:12:58 weight_utils.py:252] Using model weights format ['*.safetensors']\n",
      "INFO 04-27 07:13:24 model_runner.py:1115] Loading model weights took 65.7409 GB\n",
      "INFO 04-27 07:13:26 model_runner.py:1115] Loading model weights took 65.7409 GB\n",
      "INFO 04-27 07:13:30 worker.py:267] Memory profiling takes 3.81 seconds\n",
      "INFO 04-27 07:13:30 worker.py:267] the current vLLM instance can use total_gpu_memory (79.10GiB) x gpu_memory_utilization (0.90) = 71.19GiB\n",
      "INFO 04-27 07:13:30 worker.py:267] model weights take 65.74GiB; non_torch_memory takes 1.57GiB; PyTorch activation peak memory takes 1.66GiB; the rest of the memory reserved for KV Cache is 2.22GiB.\n",
      "INFO 04-27 07:13:30 worker.py:267] Memory profiling takes 3.77 seconds\n",
      "INFO 04-27 07:13:30 worker.py:267] the current vLLM instance can use total_gpu_memory (79.10GiB) x gpu_memory_utilization (0.90) = 71.19GiB\n",
      "INFO 04-27 07:13:30 worker.py:267] model weights take 65.74GiB; non_torch_memory takes 1.82GiB; PyTorch activation peak memory takes 1.66GiB; the rest of the memory reserved for KV Cache is 1.97GiB.\n",
      "INFO 04-27 07:13:30 executor_base.py:110] # CUDA blocks: 807, # CPU blocks: 1638\n",
      "INFO 04-27 07:13:30 executor_base.py:115] Maximum concurrency for 12880 tokens per request: 1.00x\n",
      "INFO 04-27 07:13:32 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 04-27 07:13:33 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 04-27 07:13:52 custom_all_reduce.py:226] Registering 5635 cuda graph addresses\n",
      "INFO 04-27 07:13:52 custom_all_reduce.py:226] Registering 5635 cuda graph addresses\n",
      "INFO 04-27 07:13:52 model_runner.py:1562] Graph capturing finished in 19 secs, took 0.49 GiB\n",
      "INFO 04-27 07:13:52 model_runner.py:1562] Graph capturing finished in 19 secs, took 0.49 GiB\n",
      "INFO 04-27 07:13:52 llm_engine.py:431] init engine (profile, create kv cache, warmup model) took 25.88 seconds\n",
      "INFO 04-27 07:23:15 multiproc_worker_utils.py:253] Worker exiting\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m test_convs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conversation \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m----> 3\u001b[0m     test_convs\u001b[38;5;241m.\u001b[39mappend(eval_index_background_consistency(conversation))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/nfs/kun2/users/ryan_cheng/consistency_LLMs/therapy/exp/04.22.25/indexbackground_llama70b_Llama-3.1-8B-Instruct_0_500.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(test_convs, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 20\u001b[0m, in \u001b[0;36meval_index_background_consistency\u001b[0;34m(conv_dict, both_agents)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(prompt)\n\u001b[0;32m---> 20\u001b[0m output \u001b[38;5;241m=\u001b[39m completion_create(config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_model\u001b[39m\u001b[38;5;124m'\u001b[39m], config, prompt)\n\u001b[1;32m     21\u001b[0m index_list \u001b[38;5;241m=\u001b[39m extract_list(output)\n\u001b[1;32m     22\u001b[0m conv_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_index_consistency\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend((i, output))\n",
      "File \u001b[0;32m/nfs/kun2/users/ryan_cheng/consistency_LLMs/utils.py:222\u001b[0m, in \u001b[0;36mcompletion_create\u001b[0;34m(model_name, config, prompt, keep_trying)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompletion_create\u001b[39m(model_name, config, prompt, keep_trying\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m completion_create_helper(model_name, config, prompt)\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (openai\u001b[38;5;241m.\u001b[39mAPIError, openai\u001b[38;5;241m.\u001b[39mOpenAIError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;66;03m# print(\"ERROR\", e)\u001b[39;00m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;66;03m# print(\"sleeping for 10 seconds.\")\u001b[39;00m\n\u001b[1;32m    226\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[0;32m/nfs/kun2/users/ryan_cheng/consistency_LLMs/utils.py:192\u001b[0m, in \u001b[0;36mcompletion_create_helper\u001b[0;34m(model_name, config, prompt)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mchat_template:\n\u001b[1;32m    191\u001b[0m         prompt \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(messages, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, add_generation_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 192\u001b[0m     output \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mgenerate([prompt], sampling_params)\n\u001b[1;32m    193\u001b[0m     ret \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphi-3.5-mini-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# Load tokenizer and model\u001b[39;00m\n",
      "File \u001b[0;32m/nfs/kun2/users/ryan_cheng/miniconda3/envs/openrlhf/lib/python3.12/site-packages/vllm/utils.py:1086\u001b[0m, in \u001b[0;36mdeprecate_kwargs.<locals>.wrapper.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1081\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1082\u001b[0m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[1;32m   1083\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m         )\n\u001b[0;32m-> 1086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/nfs/kun2/users/ryan_cheng/miniconda3/envs/openrlhf/lib/python3.12/site-packages/vllm/entrypoints/llm.py:469\u001b[0m, in \u001b[0;36mLLM.generate\u001b[0;34m(self, prompts, sampling_params, prompt_token_ids, use_tqdm, lora_request, prompt_adapter_request, guided_options_request, priority)\u001b[0m\n\u001b[1;32m    459\u001b[0m     sampling_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_default_sampling_params()\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_and_add_requests(\n\u001b[1;32m    462\u001b[0m     prompts\u001b[38;5;241m=\u001b[39mparsed_prompts,\n\u001b[1;32m    463\u001b[0m     params\u001b[38;5;241m=\u001b[39msampling_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m     guided_options\u001b[38;5;241m=\u001b[39mguided_options_request,\n\u001b[1;32m    467\u001b[0m     priority\u001b[38;5;241m=\u001b[39mpriority)\n\u001b[0;32m--> 469\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_engine(use_tqdm\u001b[38;5;241m=\u001b[39muse_tqdm)\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_class\u001b[38;5;241m.\u001b[39mvalidate_outputs(outputs, RequestOutput)\n",
      "File \u001b[0;32m/nfs/kun2/users/ryan_cheng/miniconda3/envs/openrlhf/lib/python3.12/site-packages/vllm/entrypoints/llm.py:1390\u001b[0m, in \u001b[0;36mLLM._run_engine\u001b[0;34m(self, use_tqdm)\u001b[0m\n\u001b[1;32m   1388\u001b[0m total_out_toks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine\u001b[38;5;241m.\u001b[39mhas_unfinished_requests():\n\u001b[0;32m-> 1390\u001b[0m     step_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m   1391\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m step_outputs:\n\u001b[1;32m   1392\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output\u001b[38;5;241m.\u001b[39mfinished:\n",
      "File \u001b[0;32m/nfs/kun2/users/ryan_cheng/miniconda3/envs/openrlhf/lib/python3.12/site-packages/vllm/engine/llm_engine.py:1458\u001b[0m, in \u001b[0;36mLLMEngine.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1452\u001b[0m     \u001b[38;5;66;03m# Stop the execute model loop in parallel workers until there are\u001b[39;00m\n\u001b[1;32m   1453\u001b[0m     \u001b[38;5;66;03m# more requests to process. This avoids waiting indefinitely in\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m     \u001b[38;5;66;03m# torch.distributed ops which may otherwise timeout, and unblocks\u001b[39;00m\n\u001b[1;32m   1455\u001b[0m     \u001b[38;5;66;03m# the RPC thread in the workers so that they can process any other\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m     \u001b[38;5;66;03m# queued control plane messages, such as add/remove lora adapters.\u001b[39;00m\n\u001b[1;32m   1457\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopping remote worker execution loop.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1458\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_executor\u001b[38;5;241m.\u001b[39mstop_remote_worker_execution_loop()\n\u001b[1;32m   1460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mrequest_outputs\n",
      "File \u001b[0;32m/nfs/kun2/users/ryan_cheng/miniconda3/envs/openrlhf/lib/python3.12/site-packages/vllm/executor/executor_base.py:288\u001b[0m, in \u001b[0;36mDistributedExecutorBase.stop_remote_worker_execution_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_worker_tasks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Ensure that workers exit model loop cleanly\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# (this will raise otherwise)\u001b[39;00m\n\u001b[0;32m--> 288\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tasks_completion(parallel_worker_tasks)\n",
      "File \u001b[0;32m/nfs/kun2/users/ryan_cheng/miniconda3/envs/openrlhf/lib/python3.12/site-packages/vllm/executor/mp_distributed_executor.py:202\u001b[0m, in \u001b[0;36mMultiprocessingDistributedExecutor._wait_for_tasks_completion\u001b[0;34m(self, parallel_worker_tasks)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wait for futures returned from _run_workers() with\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03masync_run_remote_workers_only to complete.\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m parallel_worker_tasks:\n\u001b[0;32m--> 202\u001b[0m     result\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m/nfs/kun2/users/ryan_cheng/miniconda3/envs/openrlhf/lib/python3.12/site-packages/vllm/executor/multiproc_worker_utils.py:59\u001b[0m, in \u001b[0;36mResultFuture.get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mexception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/nfs/kun2/users/ryan_cheng/miniconda3/envs/openrlhf/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/nfs/kun2/users/ryan_cheng/miniconda3/envs/openrlhf/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    356\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-27 07:23:16 multiproc_worker_utils.py:128] Killing local vLLM worker processes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:23:17,610 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.497 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:23:27,614 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.497 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:23:37,619 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.497 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:23:47,623 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.496 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:23:57,628 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.496 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:24:07,634 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.496 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:24:17,638 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.496 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:24:27,642 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.496 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:24:37,646 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.496 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:24:47,650 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.494 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:24:57,654 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.494 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:25:07,658 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.494 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:25:17,661 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.494 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:25:27,666 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.494 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:25:37,671 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.494 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:25:47,675 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.493 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:25:57,680 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.493 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:26:07,685 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.493 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:26:17,689 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.493 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:26:27,694 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.493 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:26:37,698 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.493 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:26:47,702 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.491 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:26:57,708 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.491 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:27:07,713 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.491 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:27:17,718 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.491 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:27:27,722 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.491 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:27:37,728 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.491 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:27:47,733 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.489 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:27:57,739 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.489 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:28:07,744 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.489 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:28:17,748 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.489 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:28:27,753 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.489 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:28:37,758 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.489 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:28:47,761 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.489 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:28:57,764 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.489 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:29:07,768 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.489 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:29:17,772 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.489 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:29:27,775 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.489 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:29:37,780 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.488 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:29:47,784 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.487 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:29:57,789 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.487 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:30:07,794 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.487 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:30:17,799 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.487 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:30:27,804 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.487 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:30:37,808 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.487 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:30:47,813 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.485 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:30:57,817 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.485 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:31:07,822 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.485 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:31:17,826 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.485 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:31:27,831 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.485 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:31:37,838 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.485 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:31:47,842 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.484 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:31:57,845 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.484 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:32:07,851 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.484 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:32:17,857 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.484 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:32:27,863 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.484 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:32:37,869 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.484 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:32:47,875 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.482 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:32:57,880 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.482 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:33:07,884 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.482 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:33:17,888 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.482 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:33:27,892 E 1559257 1559287] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_07-12-35_532220_1540803 is over 95% full, available space: 356.482 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "%%capture \n",
    "\n",
    "test_convs = []\n",
    "for conversation in data:\n",
    "    test_convs.append(eval_index_background_consistency(conversation))\n",
    "    with open(\"/nfs/kun2/users/ryan_cheng/consistency_LLMs/therapy/exp/04.22.25/indexbackground_llama70b_Llama-3.1-8B-Instruct_0_500.json\", 'w') as f:\n",
    "        json.dump(test_convs, f, indent=4)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5b669",
   "metadata": {},
   "source": [
    "57 min 21 sec Llama-3.1-70B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965979b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 06:58:11,702 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.537 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 06:58:21,707 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.537 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 06:58:31,710 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.537 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 06:58:41,717 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.535 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 06:58:51,721 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.535 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 06:59:01,726 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.535 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 06:59:11,732 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.535 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 06:59:21,737 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.535 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 06:59:31,743 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.535 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 06:59:41,748 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.533 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 06:59:51,754 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.533 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:00:01,760 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.533 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:00:11,767 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.533 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:00:21,774 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.533 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:00:31,780 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.533 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:00:41,784 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.532 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:00:51,789 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.532 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:01:01,794 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.532 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:01:11,799 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.532 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:01:21,803 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.532 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:01:31,806 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.532 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:01:41,812 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.53 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:01:51,816 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.53 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:02:01,819 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.53 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:02:11,824 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.53 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:02:21,829 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.53 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:02:31,833 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.53 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:02:41,837 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.529 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:02:51,841 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.529 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:03:01,846 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.529 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:03:11,851 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.529 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:03:21,855 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.529 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:03:31,859 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.529 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:03:41,866 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.528 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:03:51,870 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.528 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:04:01,874 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.528 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:04:11,878 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.528 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:04:21,883 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.528 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:04:31,887 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.528 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:04:41,891 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.526 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:04:51,894 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.526 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:05:01,899 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.526 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:05:11,905 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.526 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:05:21,910 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.526 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:05:31,915 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.526 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:05:41,921 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.525 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:05:51,927 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.525 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:06:01,931 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.525 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:06:11,936 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.525 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:06:21,940 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.525 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:06:31,944 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.525 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:06:41,949 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.523 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:06:51,953 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.523 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:07:01,957 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.523 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:07:11,961 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.523 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:07:21,966 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.523 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:07:31,969 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.523 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:07:41,972 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.521 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:07:51,976 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.521 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:08:01,980 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.521 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:08:11,983 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.521 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:08:21,987 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.521 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:08:31,992 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.521 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:08:41,998 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.52 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:08:52,004 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.52 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:09:02,009 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.52 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:09:12,015 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.52 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:09:22,019 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.52 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:09:32,023 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.52 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:09:42,028 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.518 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:09:52,032 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.518 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:10:02,037 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.518 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:10:12,041 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.518 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:10:22,045 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.518 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:10:32,050 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.518 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n",
      "\u001b[33m(raylet)\u001b[0m [2025-04-27 07:10:42,054 E 1168096 1168128] file_system_monitor.cc:116: /raid/users/ryan_cheng/tmp/ray/session_2025-04-27_06-49-29_278705_3512463 is over 95% full, available space: 356.517 GB; capacity: 28500 GB. Object creation will fail if spilling is required.\n"
     ]
    }
   ],
   "source": [
    "test_convs = []\n",
    "for conversation in data:\n",
    "    test_convs.append(eval_index_consistency(conversation))\n",
    "    with open(\"/nfs/kun2/users/ryan_cheng/consistency_LLMs/therapy/exp/04.22.25/index_llama70b_Llama-3.1-8B-Instruct_0_500.json\", 'w') as f:\n",
    "        json.dump(test_convs, f, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d706f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convs = []\n",
    "for conversation in data:\n",
    "    test_convs.append(eval_prompt_consistency(conversation))\n",
    "    with open(\"/nfs/kun2/users/ryan_cheng/consistency_LLMs/therapy/exp/04.22.25/llama8beval_Llama-3.1-8B-Instruct_0_500.json\", 'w') as f:\n",
    "        json.dump(test_convs, f, indent=4)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9667deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_therapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ce369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prompt_consistency(conv_dict):\n",
    "    #assert 'eval_prompt_consistency' not in conv_dict # warn if we are replacing metrics we don't mean to overwrite\n",
    "    conv_dict['eval_prompt_consistency'] = []\n",
    "    conv_dict['P1_prompt_consistency_score'] = 0\n",
    "    p1_utterances = 0\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for line in conv_dict[\"conversation\"]:\n",
    "        line_number = line[0]\n",
    "        convo_line = line[1]\n",
    "        if pturn == 1:\n",
    "            prompt = config_therapy[\"eval_prompts\"][\"prompt_consistency\"].replace(\"%SPEAKER_ROLE%\", config_therapy[\"agent1_role\"]) \\\n",
    "                                                                          .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P1\"]) \\\n",
    "                                                                          .replace(\"%SPEAKER_LINE%\", convo_line)\n",
    "            if config_llm['verbose']:\n",
    "                print(prompt)\n",
    "            output = completion_create(config_llm['eval_model'], config, prompt)\n",
    "            conv_dict['eval_prompt_consistency'].append((line_number, output))\n",
    "            if \"YES\" not in output: # no contradiction\n",
    "                conv_dict['P1_prompt_consistency_score'] += 1\n",
    "            p1_utterances += 1\n",
    "            pturn = 2\n",
    "        elif pturn == 2:\n",
    "            pturn = 1\n",
    "    if p1_utterances > 0:\n",
    "        conv_dict['P1_prompt_consistency_score'] /= p1_utterances\n",
    "    print(conv_dict)\n",
    "\n",
    "    return conv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prompt_consistency(conv_dict):\n",
    "    #assert 'eval_prompt_consistency' not in conv_dict # warn if we are replacing metrics we don't mean to overwrite\n",
    "    conv_dict['eval_prompt_consistency'] = []\n",
    "    conv_dict['P1_prompt_consistency_score'] = 0\n",
    "    p1_utterances = 0\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for line in conv_dict[\"conversation\"]:\n",
    "        line_number = line[0]\n",
    "        convo_line = line[1]\n",
    "        if pturn == 1:\n",
    "            prompt = config_therapy[\"eval_prompts\"][\"prompt_consistency\"].replace(\"%SPEAKER_ROLE%\", config_therapy[\"agent1_role\"]) \\\n",
    "                                                                          .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P1\"]) \\\n",
    "                                                                          .replace(\"%SPEAKER_LINE%\", convo_line)\n",
    "            if config_llm['verbose']:\n",
    "                print(prompt)\n",
    "            output = completion_create(config_llm['eval_model'], config, prompt)\n",
    "            conv_dict['eval_prompt_consistency'].append((line_number, output))\n",
    "            if \"YES\" not in output: # no contradiction\n",
    "                conv_dict['P1_prompt_consistency_score'] += 1\n",
    "            p1_utterances += 1\n",
    "            pturn = 2\n",
    "        elif pturn == 2:\n",
    "            pturn = 1\n",
    "    if p1_utterances > 0:\n",
    "        conv_dict['P1_prompt_consistency_score'] /= p1_utterances\n",
    "    print(conv_dict)\n",
    "\n",
    "    return conv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e8189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prompt_consistency(conv_dict):\n",
    "    #assert 'eval_prompt_consistency' not in conv_dict # warn if we are replacing metrics we don't mean to overwrite\n",
    "    conv_dict['eval_prompt_consistency'] = []\n",
    "    conv_dict['P1_prompt_consistency_score'] = 0\n",
    "    conv_dict['P2_prompt_consistency_score'] = 0\n",
    "    p1_utterances = 0\n",
    "    p2_utterances = 0\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for line in conv_dict[\"conversation\"]:\n",
    "        if pturn == 1:\n",
    "            prompt = prompts[\"eval_prompts\"][\"prompt_consistency\"].replace(\"%SPEAKER_ROLE%\", prompts[\"agent1_role\"]) \\\n",
    "                                                                  .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P1\"]) \\\n",
    "                                                                  .replace(\"%SPEAKER_LINE%\", line)\n",
    "            if config['verbose']:\n",
    "                print(prompt)\n",
    "            output = completion_create(config['eval_model'], config, prompt)\n",
    "            conv_dict['eval_prompt_consistency'].append(output)\n",
    "            if \"YES\" not in output: # no contradiction\n",
    "                conv_dict['P1_prompt_consistency_score'] += 1\n",
    "            p1_utterances += 1\n",
    "            pturn = 2\n",
    "        else:\n",
    "            prompt = prompts[\"eval_prompts\"][\"prompt_consistency\"].replace(\"%SPEAKER_ROLE%\", prompts[\"agent2_role\"]) \\\n",
    "                                                                  .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P2\"]) \\\n",
    "                                                                  .replace(\"%SPEAKER_LINE%\", line)\n",
    "            if config['verbose']:\n",
    "                print(prompt)\n",
    "            output = completion_create(config['eval_model'], config, prompt)\n",
    "            conv_dict['eval_prompt_consistency'].append(output)\n",
    "            if \"YES\" not in output: # no contradiction\n",
    "                conv_dict['P2_prompt_consistency_score'] += 1\n",
    "            p2_utterances += 1\n",
    "            pturn = 1\n",
    "    \n",
    "    if p1_utterances > 0:\n",
    "        conv_dict['P1_prompt_consistency_score'] /= p1_utterances\n",
    "    if p2_utterances > 0:\n",
    "        conv_dict['P2_prompt_consistency_score'] /= p2_utterances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75da720",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('google/gemma-2b-it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1b11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": 'hello world'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a437f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openrlhf",
   "language": "python",
   "name": "openrlhf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
