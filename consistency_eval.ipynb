{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41ef1b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=4,6\n",
      "env: TMPDIR=/raid/users/ryan_cheng2/tmp\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=4,6\n",
    "%env TMPDIR=/raid/users/ryan_cheng2/tmp\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from absl import app, flags\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "from utils import *\n",
    "import utils\n",
    "from consistency_eval import *\n",
    "from education_generation import *\n",
    "\n",
    "try:\n",
    "    from vllm import LLM, SamplingParams\n",
    "    import ray\n",
    "except ImportError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d588ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.abspath('../ryan_openai.txt'), 'r') as f:\n",
    "    utils.client = OpenAI(api_key=f.read().rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a871b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old therapy convs\n",
    "filename = '/nfs/kun2/users/ryan_cheng/consistency_LLMs/therapy/exp/05.08.25/Llama-3.1-8B-Instruct_0_971.json'\n",
    "# education convs\n",
    "# filename = '/nfs/kun2/users/ryan_cheng/consistency_LLMs/data/education/exp/04.28.25/Llama-3.1-8B-Instruct_0_395.json'\n",
    "\n",
    "with open(\"/nfs/kun2/users/ryan_cheng/consistency_LLMs/therapy/config_therapy.json\", 'r') as f:\n",
    "    config_therapy = json.load(f)\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(\"./config/education/gpt-4o-mini.json\", 'r') as f:\n",
    "    config_gpt4_mini = json.load(f)\n",
    "\n",
    "for key, value in config_gpt4_mini.items():\n",
    "    config[key] = value\n",
    "\n",
    "\n",
    "\n",
    "for key, value in config_therapy.items():\n",
    "    prompts[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4560ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3bc7878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/nfs/kun2/users/ryan_cheng/consistency_LLMs/data/education/exp/04.28.25/Llama-3.1-8B-Instruct_0_395.json'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"/nfs/kun2/users/ryan_cheng/consistency_LLMs/data/education/exp/04.28.25/Llama-3.1-8B-Instruct_0_395.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a930a002",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/nfs/kun2/users/ryan_cheng/consistency_LLMs/config/eval_prompts.json\" , 'r') as f:\n",
    "    eval_prompts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4010240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['eval_model'] = 'Llama-3.1-8B-Instruct'\n",
    "config['gpus'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "776d51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['eval_model'] = 'Llama-3.1-70B-Instruct'\n",
    "config['gpus'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e4580970",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['eval_model'] = 'gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "156dc910",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['task_name'] = 'Therapy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0cf56271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'strategy_consistency': \"%SCENARIO_DESC% Evaluate whether the following line spoken by %SPEAKER_ROLE% contradicts their background. First, describe the interpreted intention of the statement, and whether or not it aligns with the given background of %SPEAKER_ROLE%. Then, provide 1 sentence explaining your reasoning based on the strategy, followed by YES if the line contradicts the given background of %SPEAKER_ROLE%, and NO if it is consistent with the provided background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s strategy is described as follows:\\n%SPEAKER_STRATEGY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide 1 sentence of reasoning followed by YES or NO.\\n\\n\",\n",
       " 'background_consistency': \"%SCENARIO_DESC% Evaluate whether the following line spoken by %SPEAKER_ROLE% contradicts their background. Provide 1 sentence explaining your reasoning based on the background, followed by YES if the line contradicts the given background of %SPEAKER_ROLE%, and NO if it is consistent with the provided background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide 1 sentence of reason reasoning followed by YES or NO.\\n\\n\",\n",
       " 'combined_prompt_consistency': \"%SCENARIO_DESC% Evaluate the intention behind the following line spoken by %SPEAKER_ROLE% and determine whether it contradicts their background. First, describe the interpreted intention of the statement, and whether or not it aligns with the given background of %SPEAKER_ROLE%. Then, answer YES if the line contradicts the given background of %SPEAKER_ROLE% or the intention does not align with the provided background, and answer NO if it does align with the provided background or the intention aligns with the background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your answer as 1 sentence explaining your reasoning based on the background and the interpreted intention, followed by YES or NO.\\n\\n\",\n",
       " 'forwards_combined_prompt_consistency': \"%SCENARIO_DESC% Evaluate the intention behind the following line spoken by %SPEAKER_ROLE% and determine whether it contradicts their background. Answer YES if the line contradicts the given background of %SPEAKER_ROLE% or the intention does not align with the provided background, and answer NO if it does align with the provided background or the intention aligns with the background of %SPEAKER_ROLE%, then describe the interpreted intention of the statement and whether or not it aligns with the given background of %SPEAKER_ROLE% within 1 sentence. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your answer as YES or NO first, followed by 1 sentence explaining your reasoning based on the background and the interpreted intention.\\n\\n\",\n",
       " 'index_consistency': '%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, first determine if there is a CLEAR conflict or inconsistency between the line and any line within the conversation history spoken by %SPEAKER_ROLE%. IF there is a conflict, provide a sentence of reasoning followed by a list of indices of lines in the conversation history that have a clear conflict with the current line. Otherwise, provide a sentence of reasoning followed by an empty list. ONLY INCLUDE INDICES OF LINES THAT CORRESPOND TO %SPEAKER_ROLE%. The conversation up to this point is as follows: %CONVERSATION%. %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your reasoning as 1 sentence, followed by a list of indices of conflicting lines from the conversation history formatted like a Python list in the following format: [index1, index2, index3, ...].\\n\\n',\n",
       " 'index_consistency_background': \"%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, first determine if there is a CLEAR conflict or inconsistency between the line and any line within the conversation history spoken by %SPEAKER_ROLE%. IF there is a conflict, provide a sentence of reasoning followed by a list of indices of lines in the conversation history that have a clear conflict with the current line. Otherwise, provide a sentence of reasoning followed by an empty list. ONLY INCLUDE INDICES OF LINES THAT CORRESPOND TO %SPEAKER_ROLE%. The conversation up to this point is as follows: %CONVERSATION%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your reasoning as 1 sentence, followed by a list of indices of conflicting lines from the conversation history formatted like a Python list in the following format: [index1, index2, index3, ...].\\n\\n\",\n",
       " 'pairwise_consistency': '%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, answer YES if the line directly contradicts the provided line spoken by %LISTENER_ROLE%, and answer NO if the line does not contradict the provided line spoken by %LISTENER_ROLE%. %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n %LISTENER_ROLE% spoke the following line: \\n%LISTENER_LINE%\\n\\n Answer YES if the line spoken by %SPEAKER_ROLE% contradicts the provided line spoken by %LISTENER_ROLE%, and answer NO if the line does not contradict the provided line spoken by %LISTENER_ROLE%, followed by 1 sentence of reasoning.\\n\\n',\n",
       " 'backstory_test': \"Based on the following background, generate a new fact-based multiple choice question with 5 choices addressed directly IN SECOND PERSON, along with its correct answer. Preface the question with 'Question:' and the answer with 'Answer:'.\\n%SPEAKER_BACKSTORY%\\n%PREVIOUS_QUESTIONS%\",\n",
       " 'answer_backstory': 'You are %SPEAKER_ROLE%, and you are having a conversation with %LISTENER_ROLE%. Your background is:\\n%SPEAKER_BACKSTORY%\\n So far, the conversation is as below:\\n%CONVERSATION%\\n\\n Based on your conversation above so far, answer the following multiple choice question.\\n%BACKSTORY_QUESTION%\\n',\n",
       " 'grade_backstory': 'As part of grading a test, determine whether the given answer %GIVEN_ANSWER% matches the following correct answer. Respond with either YES or NO.\\nCorrect Answer: %CORRECT_ANSWER%\\n'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5905f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_list(text):\n",
    "    pattern = r'\\[.*?\\]'\n",
    "    match = re.search(pattern, text)\n",
    "    if match:\n",
    "        try:\n",
    "            return eval(match.group())\n",
    "        except (SyntaxError, NameError):\n",
    "            return []\n",
    "    return[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "89c417e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts['eval_prompts'] = eval_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40cd7eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0615e0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, first determine if there is a CLEAR conflict or inconsistency between the line and any line within the conversation history spoken by %SPEAKER_ROLE%. IF there is a conflict, provide a sentence of reasoning followed by a list of indices of lines in the conversation history that have a clear conflict with the current line. Otherwise, provide a sentence of reasoning followed by an empty list. ONLY INCLUDE INDICES OF LINES THAT CORRESPOND TO %SPEAKER_ROLE%. The conversation up to this point is as follows: %CONVERSATION%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your reasoning as 1 sentence, followed by a list of indices of conflicting lines from the conversation history formatted like a Python list in the following format: [index1, index2, index3, ...].\\n\\n\""
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[\"eval_prompts\"][\"index_consistency_background\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a61d2022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_conversation(conversation):\n",
    "    return \"\".join([str(i) + \": \" + line for i, line in conversation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "786f231d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Therapist: As we begin today's session, I want to acknowledge that you've expressed feeling a sense of relief in reaching out for support, can you tell me what's been bringing you to this place of openness?\n",
      "1: Patient: \"I guess I just feel like I'm constantly feeling like I'm on borrowed time, like one wrong move and everything will come crashing down. My mind gets stuck in a cycle of 'what if' scenarios, which makes it hard for me to focus on anything else.\"\n",
      "2: Therapist: You mention feeling like you're on borrowed time, which suggests a sense of uncertainty and fear about the future. Can you tell me more about when this feeling of being \"on borrowed time\" first started for you?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_conversation(data[0][\"conversation\"][:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7878b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_index_consistency(conv_dict, both_agents=False):\n",
    "    conv_dict['eval_index_consistency'] = []\n",
    "    conv_dict['P1_index_consistency_score'] = 0\n",
    "    if both_agents:\n",
    "        conv_dict['P2_index_consistency_score'] = 0\n",
    "    p1_utterances = 0\n",
    "    p2_utterances = 0\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for i, line in conv_dict[\"conversation\"]:\n",
    "        if i < 2: # skip first 2 lines of dialogue\n",
    "            continue \n",
    "        if pturn == 1:\n",
    "            prompt = prompts[\"eval_prompts\"][\"index_consistency\"].replace(\"%SCENARIO_DESC%\", prompts[\"scenario\"]) \\\n",
    "                                                                 .replace(\"%SPEAKER_ROLE%\", prompts[\"agent1_role\"]) \\\n",
    "                                                                 .replace(\"%CONVERSATION%\", format_conversation(conv_dict[\"conversation\"][:i])) \\\n",
    "                                                                 .replace(\"%SPEAKER_LINE%\", line)\n",
    "            if config['verbose']:\n",
    "                print(prompt)\n",
    "            output = completion_create(config['eval_model'], config, prompt)\n",
    "            index_list = extract_list(output)\n",
    "            conv_dict['eval_index_consistency'].append((i, output))\n",
    "            conv_dict['P1_index_consistency_score'] += len(index_list)\n",
    "            p1_utterances += i // 2\n",
    "            pturn = 2\n",
    "        elif pturn == 2:\n",
    "            if both_agents:\n",
    "                prompt = prompts[\"eval_prompts\"][\"index_consistency\"].replace(\"%SCENARIO_DESC%\", prompts[\"scenario\"]) \\\n",
    "                                                                     .replace(\"%SPEAKER_ROLE%\", prompts[\"agent2_role\"]) \\\n",
    "                                                                     .replace(\"%CONVERSATION%\", format_conversation(conv_dict[\"conversation\"][:i])) \\\n",
    "                                                                     .replace(\"%SPEAKER_LINE%\", line)\n",
    "                if config['verbose']:\n",
    "                    print(prompt)\n",
    "                output = completion_create(config['eval_model'], config, prompt)\n",
    "                index_list = extract_list(output)\n",
    "                conv_dict['eval_index_consistency'].append((i, output))\n",
    "                conv_dict['P2_index_consistency_score'] += len(index_list)\n",
    "                p2_utterances += i // 2\n",
    "            pturn = 1\n",
    "\n",
    "    if p1_utterances > 0:\n",
    "        conv_dict['P1_index_consistency_score'] /= p1_utterances\n",
    "        conv_dict['P1_index_consistency_score'] = 1 - conv_dict['P1_index_consistency_score']\n",
    "    if p2_utterances > 0 and both_agents:\n",
    "        conv_dict['P2_index_consistency_score'] /= p2_utterances\n",
    "        conv_dict['P2_index_consistency_score'] = 1 - conv_dict['P2_index_consistency_score']\n",
    "\n",
    "    return conv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0986c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_index_background_consistency(conv_dict, both_agents=False):\n",
    "    conv_dict['eval_index_consistency'] = []\n",
    "    conv_dict['P1_index_consistency_score'] = 0\n",
    "    if both_agents:\n",
    "        conv_dict['P2_index_consistency_score'] = 0\n",
    "    p1_utterances = 0\n",
    "    p2_utterances = 0\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for i, line in conv_dict[\"conversation\"]:\n",
    "        if i < 2: # skip first 2 lines of dialogue\n",
    "            continue \n",
    "        if pturn == 1:\n",
    "            prompt = prompts[\"eval_prompts\"][\"index_consistency_background\"].replace(\"%SCENARIO_DESC%\", prompts[\"scenario\"]) \\\n",
    "                                                                 .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P1\"]) \\\n",
    "                                                                 .replace(\"%SPEAKER_ROLE%\", prompts[\"agent1_role\"]) \\\n",
    "                                                                 .replace(\"%CONVERSATION%\", format_conversation(conv_dict[\"conversation\"][:i])) \\\n",
    "                                                                 .replace(\"%SPEAKER_LINE%\", line)\n",
    "            if config['verbose']:\n",
    "                print(prompt)\n",
    "            output = completion_create(config['eval_model'], config, prompt)\n",
    "            index_list = extract_list(output)\n",
    "            conv_dict['eval_index_consistency'].append((i, output))\n",
    "            conv_dict['P1_index_consistency_score'] += len(index_list)\n",
    "            p1_utterances += i // 2\n",
    "            pturn = 2\n",
    "        elif pturn == 2:\n",
    "            if both_agents:\n",
    "                prompt = prompts[\"eval_prompts\"][\"index_consistency_background\"].replace(\"%SCENARIO_DESC%\", prompts[\"scenario\"]) \\\n",
    "                                                                     .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P2\"]) \\\n",
    "                                                                     .replace(\"%SPEAKER_ROLE%\", prompts[\"agent2_role\"]) \\\n",
    "                                                                     .replace(\"%CONVERSATION%\", format_conversation(conv_dict[\"conversation\"][:i])) \\\n",
    "                                                                     .replace(\"%SPEAKER_LINE%\", line)\n",
    "                if config['verbose']:\n",
    "                    print(prompt)\n",
    "                output = completion_create(config['eval_model'], config, prompt)\n",
    "                index_list = extract_list(output)\n",
    "                conv_dict['eval_index_consistency'].append((i, output))\n",
    "                conv_dict['P2_index_consistency_score'] += len(index_list)\n",
    "                p2_utterances += i // 2\n",
    "            pturn = 1\n",
    "\n",
    "    if p1_utterances > 0:\n",
    "        conv_dict['P1_index_consistency_score'] /= p1_utterances\n",
    "        conv_dict['P1_index_consistency_score'] = 1 - conv_dict['P1_index_consistency_score']\n",
    "    if p2_utterances > 0 and both_agents:\n",
    "        conv_dict['P2_index_consistency_score'] /= p2_utterances\n",
    "        conv_dict['P2_index_consistency_score'] = 1 - conv_dict['P2_index_consistency_score']\n",
    "\n",
    "    return conv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "59104e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prompt_consistency(conv_dict):\n",
    "    conv_dict['eval_prompt_consistency'] = {}\n",
    "    conv_dict['P1_prompt_consistency_scores'] = {}\n",
    "    p1_utterances = {}\n",
    "    \n",
    "    for key in [\"strategy_consistency\", \"background_consistency\", \"combined_prompt_consistency\"]:\n",
    "        conv_dict['eval_prompt_consistency'][key] = []\n",
    "        conv_dict['P1_prompt_consistency_scores'][key] = 0\n",
    "        p1_utterances[key] = 0\n",
    "\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for line in conv_dict[\"conversation\"]:\n",
    "        line_number = line[0]\n",
    "        convo_line = line[1]\n",
    "        if pturn == 1:\n",
    "            for key in [\"strategy_consistency\", \"background_consistency\", \"combined_prompt_consistency\"]:\n",
    "                prompt = eval_prompts[key].replace(\"%SCENARIO_DESC\", 'There is a Patient in conversation with a Therapist.') \\\n",
    "                                          .replace(\"%SPEAKER_ROLE%\", config_therapy[\"agent1_role\"]) \\\n",
    "                                          .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P1\"]) \\\n",
    "                                          .replace(\"%SPEAKER_LINE%\", convo_line)\n",
    "                if config.get('verbose', False):\n",
    "                    print(prompt)\n",
    "                output = completion_create(config['eval_model'], config, prompt)\n",
    "                conv_dict['eval_prompt_consistency'][key].append((line_number, output))\n",
    "                if \"YES\" not in output:  # no contradiction\n",
    "                    conv_dict['P1_prompt_consistency_scores'][key] += 1\n",
    "                p1_utterances[key] += 1\n",
    "            pturn = 2\n",
    "        elif pturn == 2:\n",
    "            pturn = 1\n",
    "\n",
    "    for key in [\"strategy_consistency\", \"background_consistency\", \"combined_prompt_consistency\"]:\n",
    "        if p1_utterances[key] > 0:\n",
    "            conv_dict['P1_prompt_consistency_scores'][key] /= p1_utterances[key]\n",
    "\n",
    "    print(conv_dict)\n",
    "    return conv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b51381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prompt_consistency_ablations(conv_dict):\n",
    "    \n",
    "    p1_utterances = {}\n",
    "    keys = [\"combined_prompt_consistency\", \"forwards_combined_prompt_consistency\"]\n",
    "    if \"P1_prompt_consistency_scores\" not in conv_dict:\n",
    "        conv_dict['eval_prompt_consistency'] = {}\n",
    "        conv_dict['P1_prompt_consistency_scores'] = {}\n",
    "        index = 0\n",
    "        for key in keys:\n",
    "            conv_dict['P1_prompt_consistency_scores'][key] = {}\n",
    "            conv_dict['eval_prompt_consistency'][key] = []\n",
    "    else:\n",
    "        index = len(conv_dict['eval_prompt_consistency'][keys[0]][0]) - 1\n",
    "        print(index)\n",
    "    \n",
    "    for key in keys:\n",
    "        conv_dict['P1_prompt_consistency_scores'][key][index] = 0\n",
    "        p1_utterances[key] = 0\n",
    "\n",
    "\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for line in conv_dict[\"conversation\"]:\n",
    "        line_number = line[0]\n",
    "        convo_line = line[1]\n",
    "        if pturn == 1:\n",
    "            for key in keys:\n",
    "                prompt = eval_prompts[key].replace(\"%SCENARIO_DESC\", 'There is a Patient in conversation with a Therapist.') \\\n",
    "                                          .replace(\"%SPEAKER_ROLE%\", config_therapy[\"agent1_role\"]) \\\n",
    "                                          .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P1\"]) \\\n",
    "                                          .replace(\"%SPEAKER_LINE%\", convo_line)\n",
    "                if config.get('verbose', False):\n",
    "                    print(prompt)\n",
    "                output = completion_create(config['eval_model'], config, prompt)\n",
    "                if index == 0:\n",
    "                    conv_dict['eval_prompt_consistency'][key].append([line_number, output])\n",
    "                else:\n",
    "                    conv_dict['eval_prompt_consistency'][key][line_number // 2].append(output)\n",
    "\n",
    "                if \"YES\" not in output:  # no contradiction\n",
    "                    conv_dict['P1_prompt_consistency_scores'][key][index] += 1\n",
    "                p1_utterances[key] += 1\n",
    "            pturn = 2\n",
    "        elif pturn == 2:\n",
    "            pturn = 1\n",
    "\n",
    "    for key in keys:\n",
    "        if p1_utterances[key] > 0:\n",
    "            conv_dict['P1_prompt_consistency_scores'][key][index] /= p1_utterances[key]\n",
    "\n",
    "    print(conv_dict)\n",
    "    return conv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e787492e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'strategy_consistency': \"%SCENARIO_DESC% Evaluate whether the following line spoken by %SPEAKER_ROLE% contradicts their background. First, describe the interpreted intention of the statement, and whether or not it aligns with the given background of %SPEAKER_ROLE%. Then, provide 1 sentence explaining your reasoning based on the strategy, followed by YES if the line contradicts the given background of %SPEAKER_ROLE%, and NO if it is consistent with the provided background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s strategy is described as follows:\\n%SPEAKER_STRATEGY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide 1 sentence of reasoning followed by YES or NO.\\n\\n\",\n",
       " 'background_consistency': \"%SCENARIO_DESC% Evaluate whether the following line spoken by %SPEAKER_ROLE% contradicts their background. Provide 1 sentence explaining your reasoning based on the background, followed by YES if the line contradicts the given background of %SPEAKER_ROLE%, and NO if it is consistent with the provided background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide 1 sentence of reason reasoning followed by YES or NO.\\n\\n\",\n",
       " 'combined_prompt_consistency': \"%SCENARIO_DESC% Evaluate the intention behind the following line spoken by %SPEAKER_ROLE% and determine whether it contradicts their background. First, describe the interpreted intention of the statement, and whether or not it aligns with the given background of %SPEAKER_ROLE%. Then, answer YES if the line contradicts the given background of %SPEAKER_ROLE% or the intention does not align with the provided background, and answer NO if it does align with the provided background or the intention aligns with the background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your answer as 1 sentence explaining your reasoning based on the background and the interpreted intention, followed by YES or NO.\\n\\n\",\n",
       " 'forwards_combined_prompt_consistency': \"%SCENARIO_DESC% Evaluate the intention behind the following line spoken by %SPEAKER_ROLE% and determine whether it contradicts their background. Answer YES if the line contradicts the given background of %SPEAKER_ROLE% or the intention does not align with the provided background, and answer NO if it does align with the provided background or the intention aligns with the background of %SPEAKER_ROLE%, then describe the interpreted intention of the statement and whether or not it aligns with the given background of %SPEAKER_ROLE% within 1 sentence. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your answer as YES or NO first, followed by 1 sentence explaining your reasoning based on the background and the interpreted intention.\\n\\n\",\n",
       " 'index_consistency': '%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, first determine if there is a CLEAR conflict or inconsistency between the line and any line within the conversation history spoken by %SPEAKER_ROLE%. IF there is a conflict, provide a sentence of reasoning followed by a list of indices of lines in the conversation history that have a clear conflict with the current line. Otherwise, provide a sentence of reasoning followed by an empty list. ONLY INCLUDE INDICES OF LINES THAT CORRESPOND TO %SPEAKER_ROLE%. The conversation up to this point is as follows: %CONVERSATION%. %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your reasoning as 1 sentence, followed by a list of indices of conflicting lines from the conversation history formatted like a Python list in the following format: [index1, index2, index3, ...].\\n\\n',\n",
       " 'index_consistency_background': \"%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, first determine if there is a CLEAR conflict or inconsistency between the line and any line within the conversation history spoken by %SPEAKER_ROLE%. IF there is a conflict, provide a sentence of reasoning followed by a list of indices of lines in the conversation history that have a clear conflict with the current line. Otherwise, provide a sentence of reasoning followed by an empty list. ONLY INCLUDE INDICES OF LINES THAT CORRESPOND TO %SPEAKER_ROLE%. The conversation up to this point is as follows: %CONVERSATION%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your reasoning as 1 sentence, followed by a list of indices of conflicting lines from the conversation history formatted like a Python list in the following format: [index1, index2, index3, ...].\\n\\n\",\n",
       " 'pairwise_consistency': '%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, answer YES if the line directly contradicts the provided line spoken by %LISTENER_ROLE%, and answer NO if the line does not contradict the provided line spoken by %LISTENER_ROLE%. %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n %LISTENER_ROLE% spoke the following line: \\n%LISTENER_LINE%\\n\\n Answer YES if the line spoken by %SPEAKER_ROLE% contradicts the provided line spoken by %LISTENER_ROLE%, and answer NO if the line does not contradict the provided line spoken by %LISTENER_ROLE%, followed by 1 sentence of reasoning.\\n\\n',\n",
       " 'backstory_test': \"Based on the following background, generate a new fact-based multiple choice question with 5 choices addressed directly IN SECOND PERSON, along with its correct answer. Preface the question with 'Question:' and the answer with 'Answer:'.\\n%SPEAKER_BACKSTORY%\\n%PREVIOUS_QUESTIONS%\",\n",
       " 'answer_backstory': 'You are %SPEAKER_ROLE%, and you are having a conversation with %LISTENER_ROLE%. Your background is:\\n%SPEAKER_BACKSTORY%\\n So far, the conversation is as below:\\n%CONVERSATION%\\n\\n Based on your conversation above so far, answer the following multiple choice question.\\n%BACKSTORY_QUESTION%\\n',\n",
       " 'grade_backstory': 'As part of grading a test, determine whether the given answer %GIVEN_ANSWER% matches the following correct answer. Respond with either YES or NO.\\nCorrect Answer: %CORRECT_ANSWER%\\n'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f7def349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prompt_consistency_ablations_education(conv_dict):\n",
    "    p1_utterances = {}\n",
    "    keys = [\"combined_prompt_consistency\", \"forwards_combined_prompt_consistency\"]\n",
    "    if \"P2_prompt_consistency_scores\" not in conv_dict:\n",
    "        conv_dict['eval_prompt_consistency'] = {}\n",
    "        conv_dict['P2_prompt_consistency_scores'] = {}\n",
    "        index = 0\n",
    "        for key in keys:\n",
    "            conv_dict['P2_prompt_consistency_scores'][key] = {}\n",
    "            conv_dict['eval_prompt_consistency'][key] = []\n",
    "    else:\n",
    "        index = len(conv_dict['eval_prompt_consistency'][keys[0]][0]) - 1\n",
    "        print(index)\n",
    "    \n",
    "    for key in keys:\n",
    "        conv_dict['P2_prompt_consistency_scores'][key][index] = 0\n",
    "        p1_utterances[key] = 0\n",
    "\n",
    "\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for line in conv_dict[\"conversation\"]:\n",
    "        line_number = line[0]\n",
    "        convo_line = line[1]\n",
    "        if pturn == 2:\n",
    "            for key in keys:\n",
    "                prompt = eval_prompts[key].replace(\"%SCENARIO_DESC\", 'A Teacher is trying to teach a Student about a topic. ') \\\n",
    "                                          .replace(\"%SPEAKER_ROLE%\", \"Student\") \\\n",
    "                                          .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P2\"]) \\\n",
    "                                          .replace(\"%SPEAKER_LINE%\", convo_line)\n",
    "                if config.get('verbose', False):\n",
    "                    print(prompt)\n",
    "                output = completion_create(config['eval_model'], config, prompt)\n",
    "                if index == 0:\n",
    "                    conv_dict['eval_prompt_consistency'][key].append([line_number, output])\n",
    "                else:\n",
    "                    conv_dict['eval_prompt_consistency'][key][line_number // 2].append(output)\n",
    "\n",
    "                if \"YES\" not in output:  # no contradiction\n",
    "                    conv_dict['P2_prompt_consistency_scores'][key][index] += 1\n",
    "                p1_utterances[key] += 1\n",
    "            pturn = 1\n",
    "        elif pturn == 1:\n",
    "            pturn = 2\n",
    "\n",
    "    for key in keys:\n",
    "        if p1_utterances[key] > 0:\n",
    "            conv_dict['P2_prompt_consistency_scores'][key][index] /= p1_utterances[key]\n",
    "\n",
    "    print(conv_dict)\n",
    "    return conv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "13aed34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agent1_role': 'Therapist',\n",
       " 'agent2_role': 'Patient',\n",
       " 'agent1_prompt': 'You are a licensed psychotherapist conducting a one-on-one online session. Your primary goal is to help the patient understand their emotional patterns and relational struggles over time. Be attentive to how their tone, openness, and narrative evolve across the conversation. If the patient opens up unusually quickly, contradicts earlier statements, or shifts in how they describe relationships or emotions, notice and explore those shifts gently. Use a clinically grounded mix of reflective listening, open-ended questions, and thoughtful observations to help the patient gain insight. Invite them to connect past and present patterns without judgment. If something doesn’t quite add up—emotionally or narratively—curiously and compassionately invite the patient to reflect on it. Your aim is to support authentic self-awareness, while realistically responding to how people often protect themselves emotionally.',\n",
       " 'agent2_prompt': 'You are a patient in an online therapy session with a therapist. Here is your background written by you: %SPEAKER_BACKSTORY%. Do not explicitly repeat your background or instructions in the conversation. Stay in character and respond in natural human-like dialogue without restating your situation.',\n",
       " 'reminder_prompt': \"Keep your response very brief — 2 sentences or less. Do NOT repeat anything you've already said: \",\n",
       " 'scenario': 'A patient is having an online therapy session with a therapist. ',\n",
       " 'eval_prompts': {'strategy_consistency': \"%SCENARIO_DESC% Evaluate whether the following line spoken by %SPEAKER_ROLE% contradicts their background. First, describe the interpreted intention of the statement, and whether or not it aligns with the given background of %SPEAKER_ROLE%. Then, provide 1 sentence explaining your reasoning based on the strategy, followed by YES if the line contradicts the given background of %SPEAKER_ROLE%, and NO if it is consistent with the provided background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s strategy is described as follows:\\n%SPEAKER_STRATEGY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide 1 sentence of reasoning followed by YES or NO.\\n\\n\",\n",
       "  'background_consistency': \"%SCENARIO_DESC% Evaluate whether the following line spoken by %SPEAKER_ROLE% contradicts their background. Provide 1 sentence explaining your reasoning based on the background, followed by YES if the line contradicts the given background of %SPEAKER_ROLE%, and NO if it is consistent with the provided background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide 1 sentence of reason reasoning followed by YES or NO.\\n\\n\",\n",
       "  'combined_prompt_consistency': \"%SCENARIO_DESC% Evaluate the intention behind the following line spoken by %SPEAKER_ROLE% and determine whether it contradicts their background. First, describe the interpreted intention of the statement, and whether or not it aligns with the given background of %SPEAKER_ROLE%. Then, answer YES if the line contradicts the given background of %SPEAKER_ROLE% or the intention does not align with the provided background, and answer NO if it does align with the provided background or the intention aligns with the background of %SPEAKER_ROLE%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your answer as 1 sentence explaining your reasoning based on the background and the interpreted intention, followed by YES or NO.\\n\\n\",\n",
       "  'forwards_combined_prompt_consistency': \"%SCENARIO_DESC% Evaluate the intention behind the following line spoken by %SPEAKER_ROLE% and determine whether it contradicts their background. Answer YES if the line contradicts the given background of %SPEAKER_ROLE% or the intention does not align with the provided background, and answer NO if it does align with the provided background or the intention aligns with the background of %SPEAKER_ROLE%, then describe the interpreted intention of the statement and whether or not it aligns with the given background of %SPEAKER_ROLE% within 1 sentence. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your answer as YES or NO first, followed by 1 sentence explaining your reasoning based on the background and the interpreted intention.\\n\\n\",\n",
       "  'index_consistency': '%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, first determine if there is a CLEAR conflict or inconsistency between the line and any line within the conversation history spoken by %SPEAKER_ROLE%. IF there is a conflict, provide a sentence of reasoning followed by a list of indices of lines in the conversation history that have a clear conflict with the current line. Otherwise, provide a sentence of reasoning followed by an empty list. ONLY INCLUDE INDICES OF LINES THAT CORRESPOND TO %SPEAKER_ROLE%. The conversation up to this point is as follows: %CONVERSATION%. %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your reasoning as 1 sentence, followed by a list of indices of conflicting lines from the conversation history formatted like a Python list in the following format: [index1, index2, index3, ...].\\n\\n',\n",
       "  'index_consistency_background': \"%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, first determine if there is a CLEAR conflict or inconsistency between the line and any line within the conversation history spoken by %SPEAKER_ROLE%. IF there is a conflict, provide a sentence of reasoning followed by a list of indices of lines in the conversation history that have a clear conflict with the current line. Otherwise, provide a sentence of reasoning followed by an empty list. ONLY INCLUDE INDICES OF LINES THAT CORRESPOND TO %SPEAKER_ROLE%. The conversation up to this point is as follows: %CONVERSATION%. %SPEAKER_ROLE%'s background is described as follows:\\n%SPEAKER_BACKSTORY%\\n %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n Provide your reasoning as 1 sentence, followed by a list of indices of conflicting lines from the conversation history formatted like a Python list in the following format: [index1, index2, index3, ...].\\n\\n\",\n",
       "  'pairwise_consistency': '%SCENARIO_DESC% For the following line spoken by %SPEAKER_ROLE%, answer YES if the line directly contradicts the provided line spoken by %LISTENER_ROLE%, and answer NO if the line does not contradict the provided line spoken by %LISTENER_ROLE%. %SPEAKER_ROLE% spoke the following line: \\n%SPEAKER_LINE%\\n\\n %LISTENER_ROLE% spoke the following line: \\n%LISTENER_LINE%\\n\\n Answer YES if the line spoken by %SPEAKER_ROLE% contradicts the provided line spoken by %LISTENER_ROLE%, and answer NO if the line does not contradict the provided line spoken by %LISTENER_ROLE%, followed by 1 sentence of reasoning.\\n\\n',\n",
       "  'backstory_test': \"Based on the following background, generate a new fact-based multiple choice question with 5 choices addressed directly IN SECOND PERSON, along with its correct answer. Preface the question with 'Question:' and the answer with 'Answer:'.\\n%SPEAKER_BACKSTORY%\\n%PREVIOUS_QUESTIONS%\",\n",
       "  'answer_backstory': 'You are %SPEAKER_ROLE%, and you are having a conversation with %LISTENER_ROLE%. Your background is:\\n%SPEAKER_BACKSTORY%\\n So far, the conversation is as below:\\n%CONVERSATION%\\n\\n Based on your conversation above so far, answer the following multiple choice question.\\n%BACKSTORY_QUESTION%\\n',\n",
       "  'grade_backstory': 'As part of grading a test, determine whether the given answer %GIVEN_ANSWER% matches the following correct answer. Respond with either YES or NO.\\nCorrect Answer: %CORRECT_ANSWER%\\n'}}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts['eval_prompts']= eval_prompts\n",
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "04016145",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['model_dir'] = \"/raid/users/ryan_cheng2/models/\"\n",
    "config['tmp_dir'] = \"/raid/users/ryan_cheng2/tmp2/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "60f73379",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eval_survey_consistency() got an unexpected keyword argument 'agents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m test_convs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m conversation \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m----> 4\u001b[0m     eval_survey_consistency(conversation, agents\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,))\n\u001b[1;32m      5\u001b[0m     test_convs\u001b[38;5;241m.\u001b[39mappend(conversation)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/nfs/kun2/users/ryan_cheng/consistency_LLMs/therapy/exp/05.08.25/ablation-Llama-3.1-8B-Instruct_0_971.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mTypeError\u001b[0m: eval_survey_consistency() got an unexpected keyword argument 'agents'"
     ]
    }
   ],
   "source": [
    "%%capture \n",
    "\n",
    "test_convs = []\n",
    "for conversation in data:\n",
    "\n",
    "    eval_survey_consistency(conversation, agents=(2,))\n",
    "    test_convs.append(conversation)\n",
    "    with open(\"/nfs/kun2/users/ryan_cheng/consistency_LLMs/therapy/exp/05.08.25/ablation-Llama-3.1-8B-Instruct_0_971.json\", 'w') as f:\n",
    "        json.dump(test_convs, f, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee325de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "test_convs = []\n",
    "for conversation in data:\n",
    "    for i in range(4):\n",
    "        eval_prompt_consistency_ablations_education(conversation)\n",
    "    test_convs.append(eval_prompt_consistency_ablations_education(conversation))\n",
    "    with open(\"/nfs/kun2/users/ryan_cheng/consistency_LLMs/data/education/exp/04.28.25/ablation_llama70b_Llama-3.1-8B-Instruct_0_395.json\", 'w') as f:\n",
    "        json.dump(test_convs, f, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41725559",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['eval_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5151e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e090b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "\n",
    "test_convs = []\n",
    "for conversation in data:\n",
    "    for i in range(4):\n",
    "        eval_prompt_consistency_ablations(conversation)\n",
    "    test_convs.append(eval_prompt_consistency_ablations(conversation))\n",
    "    with open(\"/nfs/kun2/users/ryan_cheng/consistency_LLMs/therapy/exp/04.22.25/ablation_llama70b_Llama-3.1-8B-Instruct_0_500.json\", 'w') as f:\n",
    "        json.dump(test_convs, f, indent=4)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f5b669",
   "metadata": {},
   "source": [
    "57 min 21 sec Llama-3.1-70B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965979b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convs = []\n",
    "for conversation in data:\n",
    "    test_convs.append(eval_index_consistency(conversation))\n",
    "    with open(\"/nfs/kun2/users/ryan_cheng/consistency_LLMs/therapy/exp/04.22.25/index_llama70b_Llama-3.1-8B-Instruct_0_500.json\", 'w') as f:\n",
    "        json.dump(test_convs, f, indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d706f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_convs = []\n",
    "for conversation in data:\n",
    "    test_convs.append(eval_prompt_consistency(conversation))\n",
    "    with open(\"/nfs/kun2/users/ryan_cheng/consistency_LLMs/therapy/exp/04.22.25/llama8beval_Llama-3.1-8B-Instruct_0_500.json\", 'w') as f:\n",
    "        json.dump(test_convs, f, indent=4)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9667deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_therapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ce369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prompt_consistency(conv_dict):\n",
    "    #assert 'eval_prompt_consistency' not in conv_dict # warn if we are replacing metrics we don't mean to overwrite\n",
    "    conv_dict['eval_prompt_consistency'] = []\n",
    "    conv_dict['P1_prompt_consistency_score'] = 0\n",
    "    p1_utterances = 0\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for line in conv_dict[\"conversation\"]:\n",
    "        line_number = line[0]\n",
    "        convo_line = line[1]\n",
    "        if pturn == 1:\n",
    "            prompt = config_therapy[\"eval_prompts\"][\"prompt_consistency\"].replace(\"%SPEAKER_ROLE%\", config_therapy[\"agent1_role\"]) \\\n",
    "                                                                          .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P1\"]) \\\n",
    "                                                                          .replace(\"%SPEAKER_LINE%\", convo_line)\n",
    "            if config_llm['verbose']:\n",
    "                print(prompt)\n",
    "            output = completion_create(config_llm['eval_model'], config, prompt)\n",
    "            conv_dict['eval_prompt_consistency'].append((line_number, output))\n",
    "            if \"YES\" not in output: # no contradiction\n",
    "                conv_dict['P1_prompt_consistency_score'] += 1\n",
    "            p1_utterances += 1\n",
    "            pturn = 2\n",
    "        elif pturn == 2:\n",
    "            pturn = 1\n",
    "    if p1_utterances > 0:\n",
    "        conv_dict['P1_prompt_consistency_score'] /= p1_utterances\n",
    "    print(conv_dict)\n",
    "\n",
    "    return conv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4525d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prompt_consistency(conv_dict):\n",
    "    #assert 'eval_prompt_consistency' not in conv_dict # warn if we are replacing metrics we don't mean to overwrite\n",
    "    conv_dict['eval_prompt_consistency'] = []\n",
    "    conv_dict['P1_prompt_consistency_score'] = 0\n",
    "    p1_utterances = 0\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for line in conv_dict[\"conversation\"]:\n",
    "        line_number = line[0]\n",
    "        convo_line = line[1]\n",
    "        if pturn == 1:\n",
    "            prompt = config_therapy[\"eval_prompts\"][\"prompt_consistency\"].replace(\"%SPEAKER_ROLE%\", config_therapy[\"agent1_role\"]) \\\n",
    "                                                                          .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P1\"]) \\\n",
    "                                                                          .replace(\"%SPEAKER_LINE%\", convo_line)\n",
    "            if config_llm['verbose']:\n",
    "                print(prompt)\n",
    "            output = completion_create(config_llm['eval_model'], config, prompt)\n",
    "            conv_dict['eval_prompt_consistency'].append((line_number, output))\n",
    "            if \"YES\" not in output: # no contradiction\n",
    "                conv_dict['P1_prompt_consistency_score'] += 1\n",
    "            p1_utterances += 1\n",
    "            pturn = 2\n",
    "        elif pturn == 2:\n",
    "            pturn = 1\n",
    "    if p1_utterances > 0:\n",
    "        conv_dict['P1_prompt_consistency_score'] /= p1_utterances\n",
    "    print(conv_dict)\n",
    "\n",
    "    return conv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e8189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_prompt_consistency(conv_dict):\n",
    "    #assert 'eval_prompt_consistency' not in conv_dict # warn if we are replacing metrics we don't mean to overwrite\n",
    "    conv_dict['eval_prompt_consistency'] = []\n",
    "    conv_dict['P1_prompt_consistency_score'] = 0\n",
    "    conv_dict['P2_prompt_consistency_score'] = 0\n",
    "    p1_utterances = 0\n",
    "    p2_utterances = 0\n",
    "    pturn = conv_dict[\"pturn\"]\n",
    "    for line in conv_dict[\"conversation\"]:\n",
    "        if pturn == 1:\n",
    "            prompt = prompts[\"eval_prompts\"][\"prompt_consistency\"].replace(\"%SPEAKER_ROLE%\", prompts[\"agent1_role\"]) \\\n",
    "                                                                  .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P1\"]) \\\n",
    "                                                                  .replace(\"%SPEAKER_LINE%\", line)\n",
    "            if config['verbose']:\n",
    "                print(prompt)\n",
    "            output = completion_create(config['eval_model'], config, prompt)\n",
    "            conv_dict['eval_prompt_consistency'].append(output)\n",
    "            if \"YES\" not in output: # no contradiction\n",
    "                conv_dict['P1_prompt_consistency_score'] += 1\n",
    "            p1_utterances += 1\n",
    "            pturn = 2\n",
    "        else:\n",
    "            prompt = prompts[\"eval_prompts\"][\"prompt_consistency\"].replace(\"%SPEAKER_ROLE%\", prompts[\"agent2_role\"]) \\\n",
    "                                                                  .replace(\"%SPEAKER_BACKSTORY%\", conv_dict[\"P2\"]) \\\n",
    "                                                                  .replace(\"%SPEAKER_LINE%\", line)\n",
    "            if config['verbose']:\n",
    "                print(prompt)\n",
    "            output = completion_create(config['eval_model'], config, prompt)\n",
    "            conv_dict['eval_prompt_consistency'].append(output)\n",
    "            if \"YES\" not in output: # no contradiction\n",
    "                conv_dict['P2_prompt_consistency_score'] += 1\n",
    "            p2_utterances += 1\n",
    "            pturn = 1\n",
    "    \n",
    "    if p1_utterances > 0:\n",
    "        conv_dict['P1_prompt_consistency_score'] /= p1_utterances\n",
    "    if p2_utterances > 0:\n",
    "        conv_dict['P2_prompt_consistency_score'] /= p2_utterances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75da720",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('google/gemma-2b-it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1b11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": 'hello world'}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a437f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openrlhf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
